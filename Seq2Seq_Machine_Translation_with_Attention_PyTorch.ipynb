{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_Machine_Translation_with_Attention_PyTorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glBo7vBLYtzt",
        "colab_type": "text"
      },
      "source": [
        "# DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMRIsf3tBdDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu2PC4k1M_5c",
        "colab_type": "code",
        "outputId": "6833f76d-a8de-46f0-988b-15ace2bad07e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvgBu6VJpgnl",
        "colab_type": "code",
        "outputId": "4698d73d-d4d6-4a13-cb3e-51c172946f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!wget -c https://raw.githubusercontent.com/udacity/aind2-nlp-capstone/master/data/small_vocab_en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-01 19:02:13--  https://raw.githubusercontent.com/udacity/aind2-nlp-capstone/master/data/small_vocab_en\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9085267 (8.7M) [text/plain]\n",
            "Saving to: ‘small_vocab_en’\n",
            "\n",
            "\rsmall_vocab_en        0%[                    ]       0  --.-KB/s               \rsmall_vocab_en      100%[===================>]   8.66M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-05-01 19:02:13 (85.1 MB/s) - ‘small_vocab_en’ saved [9085267/9085267]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQIa-WuSp_9V",
        "colab_type": "code",
        "outputId": "c029af1f-f3cb-4ee1-e938-ecf0d8e78831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!wget -c https://raw.githubusercontent.com/udacity/aind2-nlp-capstone/master/data/small_vocab_fr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-01 19:02:15--  https://raw.githubusercontent.com/udacity/aind2-nlp-capstone/master/data/small_vocab_fr\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10135742 (9.7M) [text/plain]\n",
            "Saving to: ‘small_vocab_fr’\n",
            "\n",
            "\rsmall_vocab_fr        0%[                    ]       0  --.-KB/s               \rsmall_vocab_fr      100%[===================>]   9.67M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-05-01 19:02:15 (88.2 MB/s) - ‘small_vocab_fr’ saved [10135742/10135742]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSS-UgCnoASv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  \n",
        "import os\n",
        "\n",
        "\n",
        "def load_data(path):\n",
        "    \"\"\"\n",
        "    Load dataset\n",
        "    \"\"\"\n",
        "    input_file = os.path.join(path)\n",
        "    with open(input_file, \"r\") as f:\n",
        "        data = f.read()\n",
        "\n",
        "    return data.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxhFOuZXqE8a",
        "colab_type": "code",
        "outputId": "c4713551-e860-457c-a38e-7a900cb227ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "# Load English data\n",
        "english_sentences = load_data('small_vocab_en')\n",
        "# Load French data\n",
        "french_sentences = load_data('small_vocab_fr')\n",
        "\n",
        "print('Dataset Loaded')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBqcYL0gUSr4",
        "colab_type": "code",
        "outputId": "d83d4189-570a-4a5d-c35d-4c35178629d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "english_sentences[:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['new jersey is sometimes quiet during autumn , and it is snowy in april .',\n",
              " 'the united states is usually chilly during july , and it is usually freezing in november .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-Jsm1pp8d0C",
        "colab_type": "code",
        "outputId": "ece41c8d-dce7-43f8-b3cc-8c2224745f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "french_sentences[:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\",\n",
              " 'les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nx7q5Mc6ybd",
        "colab_type": "code",
        "outputId": "cd3eea00-743d-455c-f7d0-b4b050b8a9ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "for sample_i in range(5):\n",
        "    print('English sample {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
        "    print('French sample {}:  {}\\n'.format(sample_i + 1, french_sentences[sample_i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English sample 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
            "French sample 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
            "\n",
            "English sample 2:  the united states is usually chilly during july , and it is usually freezing in november .\n",
            "French sample 2:  les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
            "\n",
            "English sample 3:  california is usually quiet during march , and it is usually hot in june .\n",
            "French sample 3:  california est généralement calme en mars , et il est généralement chaud en juin .\n",
            "\n",
            "English sample 4:  the united states is sometimes mild during june , and it is cold in september .\n",
            "French sample 4:  les états-unis est parfois légère en juin , et il fait froid en septembre .\n",
            "\n",
            "English sample 5:  your least liked fruit is the grape , but my least liked is the apple .\n",
            "French sample 5:  votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgLzox7q4NcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "# Check for a GPU\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if not train_on_gpu:\n",
        "    print('No GPU found. Please use a GPU to train your neural network.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vWIH790Y2hP",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Htui7_6pW0Z",
        "colab_type": "text"
      },
      "source": [
        "## Removing Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBip0OwqhGy6",
        "colab_type": "code",
        "outputId": "aa905de8-891a-43e9-9348-53db931bfadc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from collections import Counter\n",
        "# outlier sentences stats\n",
        "english_sentences_lens = Counter([len(x) for x in english_sentences])\n",
        "print(\"Zero-length english_sentences: {}\".format(english_sentences_lens[0]))\n",
        "print(\"Maximum english_sentence length: {}\".format(max(english_sentences_lens)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zero-length english_sentences: 1\n",
            "Maximum english_sentence length: 102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufyd-DLUhrA9",
        "colab_type": "code",
        "outputId": "c7f749f0-0b5e-467f-8754-fc4546aca1db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# outlier sentences stats\n",
        "french_sentences_lens = Counter([len(x) for x in french_sentences])\n",
        "print(\"Zero-length french_sentences: {}\".format(french_sentences_lens[0]))\n",
        "print(\"Maximum french_sentence length: {}\".format(max(french_sentences_lens)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zero-length french_sentences: 1\n",
            "Maximum french_sentence length: 114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxsaRbCgi1kw",
        "colab_type": "code",
        "outputId": "24f64e2e-281c-4ed8-cdc6-bde77171cfa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print('Number of english_sentences before removing outliers: ', len(english_sentences))\n",
        "print('Number of frenchh_sentences before removing outliers: ', len(french_sentences))\n",
        "## remove any reviews/labels with zero length from the reviews_ints list.\n",
        "\n",
        "# get indices of any reviews with length 0\n",
        "#non_zero_idx = [ii for ii, sentence in enumerate(english_sentences) if len( sentence) == 0]\n",
        "english_zero_idx = [ii for ii, sentence in enumerate(english_sentences) if len(sentence) == 0]\n",
        "french_zero_idx = [ii for ii, sentence in enumerate(french_sentences) if len(sentence) == 0]\n",
        "\n",
        "print(\"idx of english_sentence with zero legnth {}\".format(english_zero_idx))\n",
        "print(\"idx of french_sentence with zero legnth {}\".format(french_zero_idx))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of english_sentences before removing outliers:  137861\n",
            "Number of frenchh_sentences before removing outliers:  137861\n",
            "idx of english_sentence with zero legnth [137860]\n",
            "idx of french_sentence with zero legnth [137860]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2P1omQTjT-T",
        "colab_type": "code",
        "outputId": "18873104-0671-437d-9411-0fc221d6a22f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "english_sentences[-3:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['france is never chilly during january , but it is never mild in october .',\n",
              " 'the orange is her favorite fruit , but the banana is your favorite .',\n",
              " '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFt26K-kMLd",
        "colab_type": "code",
        "outputId": "ea1a72a4-56d2-4dd4-f4af-ce541eba64ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "french_sentences[-3:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['la france est jamais froid en janvier , mais il est jamais doux en octobre .',\n",
              " \"l'orange est son fruit préféré , mais la banane est votre favori .\",\n",
              " '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yct2Ny_cnSIq",
        "colab_type": "code",
        "outputId": "f9b6b81a-6e37-4481-db2f-3ead856ce11f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "english_sentences.pop(english_zero_idx[0])\n",
        "french_sentences.pop(french_zero_idx[0])\n",
        "print('Number of english_sentences after removing outliers: ', len(english_sentences))\n",
        "print('Number of frenchh_sentences after removing outliers: ', len(french_sentences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of english_sentences after removing outliers:  137860\n",
            "Number of frenchh_sentences after removing outliers:  137860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QxoFC4iZWB-",
        "colab_type": "text"
      },
      "source": [
        "## 1 - Tokenize\n",
        "\n",
        "Tokenize the words into ids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAiegro8vUf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def delimit_sentence(w):\n",
        "    w = '<sos>' + ' ' + w + ' '+ '<eos>'\n",
        "    return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP1eW79X64PS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ii, sentence in enumerate(english_sentences):\n",
        "    english_sentences[ii] = delimit_sentence(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zctrnUCU7P3s",
        "colab_type": "code",
        "outputId": "9c077211-2fa6-4d0d-c70a-6bfa278b1896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "english_sentences[:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos> new jersey is sometimes quiet during autumn , and it is snowy in april . <eos>',\n",
              " '<sos> the united states is usually chilly during july , and it is usually freezing in november . <eos>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOfdGPOG7Y7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ii, sentence in enumerate(french_sentences):\n",
        "    french_sentences[ii] = delimit_sentence(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxXRGEqH7ew7",
        "colab_type": "code",
        "outputId": "e1c3d235-e02f-4519-c09c-bb8cff476bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "french_sentences[:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"<sos> new jersey est parfois calme pendant l' automne , et il est neigeux en avril . <eos>\",\n",
              " '<sos> les états-unis est généralement froid en juillet , et il gèle habituellement en novembre . <eos>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSLQ0Vokm4pH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from string import punctuation\n",
        "\n",
        "def Tokenizer(sentences):\n",
        "  \n",
        "  words = []\n",
        "  for sentence in sentences:\n",
        "    for word in sentence.split():\n",
        "      if word not in punctuation:\n",
        "        words.append(word)\n",
        "\n",
        "  return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW7vW36h3_E4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "def create_lookup_tables(text):\n",
        "    \"\"\"\n",
        "    Create lookup tables for vocabulary\n",
        "    :param text: The text of tv scripts split into words\n",
        "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
        "    \"\"\"\n",
        "    # TODO: Implement Function\n",
        "    words_count = Counter(text) \n",
        "    sorted_vocab = sorted(words_count, key=words_count.get, reverse=True)\n",
        "    \n",
        "    #vocab_to_int = {word: ii for ii, word in enumerate(sorted_vocab, 1)}\n",
        "    \n",
        "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab,1)}\n",
        "    int_to_vocab[0] = '<pad>'\n",
        "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
        "    \n",
        "    # return tuple\n",
        "    return vocab_to_int, int_to_vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pq7S6tw-ZDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Tokenize(text):\n",
        "  \n",
        "  words = Tokenizer(text)\n",
        "  vocab_to_int, int_to_vocab = create_lookup_tables(words)\n",
        "  \n",
        "  sentences_ints = []\n",
        "  for sentence in text:\n",
        "    sentences_ints.append([vocab_to_int[word] for word in sentence.split() if word not in punctuation])\n",
        "  \n",
        "  return sentences_ints, vocab_to_int, int_to_vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OoBMqJbOqDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_sentences_ints, english_vocab_to_int, english_int_to_vocab = Tokenize(english_sentences)\n",
        "french_sentences_ints, french_vocab_to_int, french_int_to_vocab = Tokenize(french_sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-xy5sPvfdKg",
        "colab_type": "code",
        "outputId": "b220a249-2323-4be0-a8b2-8a9c331a0143",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "english_sentences_ints[:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 19, 25, 1, 10, 69, 6, 41, 9, 5, 1, 57, 4, 46, 3],\n",
              " [2, 7, 22, 23, 1, 11, 64, 6, 45, 9, 5, 1, 11, 53, 4, 47, 3]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y2Kdh4WAnvX",
        "colab_type": "text"
      },
      "source": [
        "## 2-  Padding\n",
        "\n",
        " Add padding to make all the sequences the same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M1D_eeOWvxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def pad(vocab_ints, seq_length=None):\n",
        " \n",
        "    if (seq_length==None):\n",
        "        max_len = 0 \n",
        "        for x in vocab_ints:\n",
        "          if len(x) > max_len:\n",
        "            max_len = len(x)\n",
        "        seq_length = max_len\n",
        "        \n",
        "    # getting the correct rows x cols shape\n",
        "    features = np.zeros((len(vocab_ints), seq_length), dtype=int)\n",
        "\n",
        "    \n",
        "    for i, row in enumerate(vocab_ints):\n",
        "      trunc = row[:seq_length]\n",
        "      features[i, :len(trunc)] = trunc\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab0iywWn93y-",
        "colab_type": "code",
        "outputId": "e7b3e6c4-48f7-40af-da93-f510f0dc55cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "english_features = pad(english_sentences_ints)\n",
        "english_features[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2, 19, 25,  1, 10, 69,  6, 41,  9,  5,  1, 57,  4, 46,  3,  0,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32z1aI_gyooy",
        "colab_type": "code",
        "outputId": "0e2b10ab-746d-4c82-8e5f-4246fb03cdd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "french_features = pad(french_sentences_ints)\n",
        "french_features[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  2,  36,  35,   1,  10,  68,  38,  13,  26,   8,   5,   1, 113,\n",
              "         4,  51,   3,   0,   0,   0,   0,   0,   0,   0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6y0dXOLs_t3",
        "colab_type": "code",
        "outputId": "b7fee3e5-68a2-48a9-f70e-b6d25fafdc3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "english_seq_length = 15\n",
        "\n",
        "english_features = pad(english_sentences_ints, seq_length=english_seq_length)\n",
        "english_features[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2, 19, 25,  1, 10, 69,  6, 41,  9,  5,  1, 57,  4, 46,  3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrhTJGkay4-0",
        "colab_type": "code",
        "outputId": "6a6239e9-9cea-4dc5-ff2f-afcde4a8415b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "french_seq_length = 21\n",
        "\n",
        "french_features = pad(french_sentences_ints, seq_length = french_seq_length)\n",
        "french_features[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  2,  36,  35,   1,  10,  68,  38,  13,  26,   8,   5,   1, 113,\n",
              "         4,  51,   3,   0,   0,   0,   0,   0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAlaI-4mA2ei",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybTVjFPpA-Ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(x, y):\n",
        "    \"\"\"\n",
        "    Preprocess x and y\n",
        "    :param x: Feature List of sentences\n",
        "    :param y: Label List of sentences\n",
        "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
        "    \"\"\"\n",
        "    preprocess_x, x_tk, x_tk_rev = Tokenize(x)\n",
        "    preprocess_y, y_tk, y_tk_rev = Tokenize(y)\n",
        "\n",
        "    preprocess_x = pad(preprocess_x,23)\n",
        "    preprocess_y = pad(preprocess_y,23)\n",
        "\n",
        "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
        "    #preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "\n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk, x_tk_rev, y_tk_rev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnh5Qc3WBOsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_features, french_features, english_tokenizer, french_tokenizer, english_tokenizer_rev, french_tokenizer_rev = preprocess(english_sentences, french_sentences)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0cbjHvVB0fe",
        "colab_type": "code",
        "outputId": "d3053f1f-58a2-451d-9595-22637bf13eb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "french_features.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137860, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OVJoROsB5pf",
        "colab_type": "code",
        "outputId": "107c361f-25ee-4d8e-e9a3-6375b2dfeecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "english_features.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137860, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihlbRwc8pmBX",
        "colab_type": "text"
      },
      "source": [
        "## Prep_Orig"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTiZ69XRng4r",
        "colab_type": "code",
        "outputId": "2abe8c0f-2c18-4092-dd2e-4f5b11899a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# Tokenize Example output\n",
        "text_sentences = [\n",
        "    'The quick brown fox jumps over the lazy dog .',\n",
        "    'By Jove , my quick study of lexicography won a prize .',\n",
        "    'This is a short sentence .']\n",
        "text_tokenized, text_tokenizer, text_tokenizer_rev = Tokenize(text_sentences)\n",
        "print(text_tokenized)\n",
        "print()\n",
        "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
        "    print('Sequence {} in x'.format(sample_i + 1))\n",
        "    print('  Input:  {}'.format(sent))\n",
        "    print('  Output: {}'.format(token_sent))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 1, 4, 5, 6, 7, 8, 9, 10], [11, 12, 13, 1, 14, 15, 16, 17, 2, 18], [19, 20, 2, 21, 22]]\n",
            "\n",
            "Sequence 1 in x\n",
            "  Input:  The quick brown fox jumps over the lazy dog .\n",
            "  Output: [3, 1, 4, 5, 6, 7, 8, 9, 10]\n",
            "Sequence 2 in x\n",
            "  Input:  By Jove , my quick study of lexicography won a prize .\n",
            "  Output: [11, 12, 13, 1, 14, 15, 16, 17, 2, 18]\n",
            "Sequence 3 in x\n",
            "  Input:  This is a short sentence .\n",
            "  Output: [19, 20, 2, 21, 22]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2JCsAar8E54",
        "colab_type": "code",
        "outputId": "7a80e449-afa9-4c57-8695-51f3519c76c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Pad Tokenized output\n",
        "test_pad = pad(text_tokenized)\n",
        "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
        "    print('Sequence {} in x'.format(sample_i + 1))\n",
        "    print('  Input:  {}'.format(np.array(token_sent)))\n",
        "    print('  Output: {}'.format(pad_sent))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence 1 in x\n",
            "  Input:  [ 3  1  4  5  6  7  8  9 10]\n",
            "  Output: [ 3  1  4  5  6  7  8  9 10  0]\n",
            "Sequence 2 in x\n",
            "  Input:  [11 12 13  1 14 15 16 17  2 18]\n",
            "  Output: [11 12 13  1 14 15 16 17  2 18]\n",
            "Sequence 3 in x\n",
            "  Input:  [19 20  2 21 22]\n",
            "  Output: [19 20  2 21 22  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7b3y4kjqFHu",
        "colab_type": "code",
        "outputId": "a98516f4-a300-4ec2-9003-ff7920c2b66b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "for sample_i in range(5):\n",
        "    print('small_vocab_en Line {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
        "    print('small_vocab_fr Line {}:  {}'.format(sample_i + 1, french_sentences[sample_i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "small_vocab_en Line 1:  <sos> new jersey is sometimes quiet during autumn , and it is snowy in april . <eos>\n",
            "small_vocab_fr Line 1:  <sos> new jersey est parfois calme pendant l' automne , et il est neigeux en avril . <eos>\n",
            "small_vocab_en Line 2:  <sos> the united states is usually chilly during july , and it is usually freezing in november . <eos>\n",
            "small_vocab_fr Line 2:  <sos> les états-unis est généralement froid en juillet , et il gèle habituellement en novembre . <eos>\n",
            "small_vocab_en Line 3:  <sos> california is usually quiet during march , and it is usually hot in june . <eos>\n",
            "small_vocab_fr Line 3:  <sos> california est généralement calme en mars , et il est généralement chaud en juin . <eos>\n",
            "small_vocab_en Line 4:  <sos> the united states is sometimes mild during june , and it is cold in september . <eos>\n",
            "small_vocab_fr Line 4:  <sos> les états-unis est parfois légère en juin , et il fait froid en septembre . <eos>\n",
            "small_vocab_en Line 5:  <sos> your least liked fruit is the grape , but my least liked is the apple . <eos>\n",
            "small_vocab_fr Line 5:  <sos> votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme . <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f0MSgQ0rOhq",
        "colab_type": "code",
        "outputId": "4b8a8770-cf17-4055-8143-221c202feb52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "english_words_counter = Counter([word for sentence in english_sentences for word in sentence.split()])\n",
        "french_words_counter = Counter([word for sentence in french_sentences for word in sentence.split()])\n",
        "\n",
        "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
        "print('{} unique English words.'.format(len(english_words_counter)))\n",
        "print('10 Most common words in the English dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
        "print()\n",
        "print('{} French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n",
        "print('{} unique French words.'.format(len(french_words_counter)))\n",
        "print('10 Most common words in the French dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2098970 English words.\n",
            "229 unique English words.\n",
            "10 Most common words in the English dataset:\n",
            "\"is\" \",\" \"<sos>\" \"<eos>\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\"\n",
            "\n",
            "2237015 French words.\n",
            "357 unique French words.\n",
            "10 Most common words in the French dataset:\n",
            "\"est\" \"<sos>\" \"<eos>\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpcnk2Pf-mDH",
        "colab_type": "code",
        "outputId": "26f95873-05d3-4604-fb01-a514d44d5c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer, english_tokenizer_rev, french_tokenizer_rev =\\\n",
        "    preprocess(english_sentences, french_sentences)\n",
        "    \n",
        "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
        "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
        "english_vocab_size = len(english_tokenizer)\n",
        "french_vocab_size = len(french_tokenizer)\n",
        "\n",
        "print('Data Preprocessed')\n",
        "print(\"Max English sentence length:\", max_english_sequence_length)\n",
        "print(\"Max French sentence length:\", max_french_sequence_length)\n",
        "print(\"English vocabulary size:\", english_vocab_size)\n",
        "print(\"French vocabulary size:\", french_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Preprocessed\n",
            "Max English sentence length: 23\n",
            "Max French sentence length: 23\n",
            "English vocabulary size: 227\n",
            "French vocabulary size: 354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arZbTS6hsLwk",
        "colab_type": "text"
      },
      "source": [
        "## Training, Validation, Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxVg7cW6sPp0",
        "colab_type": "code",
        "outputId": "21908170-e9b1-4aff-e45d-00ac2d342ed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "split_frac = 0.8\n",
        "\n",
        "## split data into training, validation, and test data (features and labels, x and y)\n",
        "\n",
        "\n",
        "split_idx = int(len(english_features)*split_frac)\n",
        "train_x, remaining_x = english_features[:split_idx], english_features[split_idx:]\n",
        "train_y, remaining_y = french_features[:split_idx], french_features[split_idx:]\n",
        "\n",
        "test_idx = int(len(remaining_x)*0.5)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "## print out the shapes of your resultant feature data\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
        "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))\n",
        "\n",
        "## print out the shapes of your resultant feature data\n",
        "print(\"\\t\\t\\tTarget Shapes:\")\n",
        "print(\"Train Targets: \\t\\t{}\".format(train_y.shape), \n",
        "      \"\\nValidation Targets: \\t{}\".format(val_y.shape),\n",
        "      \"\\nTest Targets: \\t\\t{}\".format(test_y.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(110288, 23) \n",
            "Validation set: \t(13786, 23) \n",
            "Test set: \t\t(13786, 23)\n",
            "\t\t\tTarget Shapes:\n",
            "Train Targets: \t\t(110288, 23) \n",
            "Validation Targets: \t(13786, 23) \n",
            "Test Targets: \t\t(13786, 23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg83ku7XtKGR",
        "colab_type": "text"
      },
      "source": [
        "## DataLoaders and Batching\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjewtpMptX0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 64\n",
        "\n",
        "# make sure the SHUFFLE your training data\n",
        "#train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "#valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "#test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRurjqofFEeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloaders = {\n",
        "    'train': DataLoader(train_data, shuffle=True, batch_size=batch_size),\n",
        "    'valid': DataLoader(valid_data, shuffle=True, batch_size=batch_size),\n",
        "    'test': DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
        "}\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D3FzlQhStlW",
        "colab_type": "code",
        "outputId": "1c2d31ef-0ae3-4976-ffb8-ee381f03078a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "\n",
        "dataset_sizes = {\n",
        "    'train': len(train_data),\n",
        "    'valid': len(valid_data),\n",
        "    'test': len(test_data),\n",
        "}\n",
        "                \n",
        "print(dataset_sizes['train'])\n",
        "print(dataset_sizes['valid'])\n",
        "print(dataset_sizes['test'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "110288\n",
            "13786\n",
            "13786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuenoU4VFnDu",
        "colab_type": "code",
        "outputId": "065987cc-ea3f-419b-a868-a89cf9d65060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(dataloaders['train'])\n",
        "sample_x, sample_y = dataiter.next()\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([64, 23])\n",
            "Sample input: \n",
            " tensor([[ 2, 24,  1,  ...,  0,  0,  0],\n",
            "        [ 2, 21,  1,  ...,  0,  0,  0],\n",
            "        [ 2, 19, 25,  ...,  0,  0,  0],\n",
            "        ...,\n",
            "        [ 2, 52, 13,  ...,  0,  0,  0],\n",
            "        [ 2, 27,  1,  ...,  0,  0,  0],\n",
            "        [ 2, 51, 13,  ...,  0,  0,  0]])\n",
            "\n",
            "Sample label size:  torch.Size([64, 23])\n",
            "Sample label: \n",
            " tensor([[  2, 102,   1,  ...,   0,   0,   0],\n",
            "        [  2,  13,  32,  ...,   0,   0,   0],\n",
            "        [  2,  36,  35,  ...,   0,   0,   0],\n",
            "        ...,\n",
            "        [  2,  65,  18,  ...,   0,   0,   0],\n",
            "        [  2,  37,   1,  ...,   0,   0,   0],\n",
            "        [  2,  62,  18,  ...,   0,   0,   0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk94XCL7itX0",
        "colab_type": "code",
        "outputId": "88370f0d-79c0-41fa-992b-8110de822e37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "x = sample_x.transpose(0, 1)\n",
        "y = sample_y.transpose(0, 1)\n",
        "\n",
        "print('Sample input size: ', x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', x)\n",
        "print()\n",
        "print('Sample label size: ', y.size()) # batch_size\n",
        "print('Sample label: \\n', y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([23, 64])\n",
            "Sample input: \n",
            " tensor([[ 2,  2,  2,  ...,  2,  2,  2],\n",
            "        [24, 21, 19,  ..., 52, 27, 51],\n",
            "        [ 1,  1, 25,  ..., 13,  1, 13],\n",
            "        ...,\n",
            "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
            "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
            "        [ 0,  0,  0,  ...,  0,  0,  0]])\n",
            "\n",
            "Sample label size:  torch.Size([23, 64])\n",
            "Sample label: \n",
            " tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [102,  13,  36,  ...,  65,  37,  62],\n",
            "        [  1,  32,  35,  ...,  18,   1,  18],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,   0,   0],\n",
            "        [  0,   0,   0,  ...,   0,   0,   0],\n",
            "        [  0,   0,   0,  ...,   0,   0,   0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFSmVjnBvgYi",
        "colab_type": "code",
        "outputId": "45dac167-5345-4139-aa75-c7b53b7fdf38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample_x0 = sample_x[-1].cpu().detach().numpy()\n",
        "\n",
        "' '.join([english_tokenizer_rev[x] for x in sample_x0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<sos> our least favorite fruit is the peach but their least favorite is the strawberry <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ej_EJPKusEJ",
        "colab_type": "code",
        "outputId": "1e96e942-6bb6-4a43-d056-5685297a6c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "sample_y[-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2,  62,  18,  19,  15,   1,   9,  91,   7,  65,  15, 142,   1,   9,\n",
              "         90,   3,   0,   0,   0,   0,   0,   0,   0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qfJ7SoazW8F",
        "colab_type": "code",
        "outputId": "3451d218-ba09-4553-c3de-b9fad4f6a681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample_y0 = sample_y[-1].cpu().detach().numpy()\n",
        "\n",
        "' '.join([french_tokenizer_rev[x] for x in sample_y0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<sos> notre fruit préféré moins est la pêche mais leur moins préférée est la fraise <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex-Pu_H6x8Q6",
        "colab_type": "code",
        "outputId": "3eb9f358-7c37-4ee6-dfa8-08ba67204183",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "    \"\"\"\n",
        "    Turn logits from a neural network into text using the tokenizer\n",
        "    :param logits: Logits from a neural network\n",
        "    :param tokenizer: Keras Tokenizer fit on the labels\n",
        "    :return: String that represents the text of the logits\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    return ' '.join([tokenizer[prediction] for prediction in np.argmax(logits, 1)])\n",
        "\n",
        "print('`logits_to_text` function loaded.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`logits_to_text` function loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqCAz89RA1d-",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4OQ6tXa_2fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgLkuwL6WpHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import random\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embed_size, hidden_size,\n",
        "                 n_layers=1, dropout=0.5):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embed_size = embed_size\n",
        "        self.embed = nn.Embedding(input_size, embed_size)\n",
        "        self.gru = nn.GRU(embed_size, hidden_size, n_layers,\n",
        "                          dropout=dropout, bidirectional=True)\n",
        "\n",
        "    def forward(self, src, hidden=None):\n",
        "        embedded = self.embed(src)\n",
        "        outputs, hidden = self.gru(embedded, hidden)\n",
        "        # sum bidirectional outputs\n",
        "        outputs = (outputs[:, :, :self.hidden_size] +\n",
        "                   outputs[:, :, self.hidden_size:])\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(Attention, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
        "        stdv = 1. / math.sqrt(self.v.size(0))\n",
        "        self.v.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        timestep = encoder_outputs.size(0)\n",
        "        h = hidden.repeat(timestep, 1, 1).transpose(0, 1)\n",
        "        encoder_outputs = encoder_outputs.transpose(0, 1)  # [B*T*H]\n",
        "        attn_energies = self.score(h, encoder_outputs)\n",
        "        return F.relu(attn_energies).unsqueeze(1)\n",
        "\n",
        "    def score(self, hidden, encoder_outputs):\n",
        "        # [B*T*2H]->[B*T*H]\n",
        "        energy = F.softmax(self.attn(torch.cat([hidden, encoder_outputs], 2)), dim=2)\n",
        "        \n",
        "        energy = energy.transpose(1, 2)  # [B*H*T]\n",
        "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)  # [B*1*H]\n",
        "        energy = torch.bmm(v, energy)  # [B*1*T]\n",
        "        return energy.squeeze(1)  # [B*T]\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size, output_size,\n",
        "                 n_layers=1, dropout=0.2):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.embed = nn.Embedding(output_size, embed_size)\n",
        "        self.dropout = nn.Dropout(dropout, inplace=True)\n",
        "        self.attention = Attention(hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size + embed_size, hidden_size,\n",
        "                          n_layers, dropout=dropout)\n",
        "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
        "\n",
        "    def forward(self, input, last_hidden, encoder_outputs):\n",
        "        # Get the embedding of the current input word (last output word)\n",
        "        embedded = self.embed(input).unsqueeze(0)  # (1,B,N)\n",
        "        embedded = self.dropout(embedded)\n",
        "        # Calculate attention weights and apply to encoder outputs\n",
        "        attn_weights = self.attention(last_hidden[-1], encoder_outputs)\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))  # (B,1,N)\n",
        "        context = context.transpose(0, 1)  # (1,B,N)\n",
        "        #print(context.size())\n",
        "        #print(embedded.size())\n",
        "        embedded = embedded.squeeze(2)\n",
        "        #print(embedded.size())\n",
        "        # Combine embedded input word and attended context, run through RNN\n",
        "        rnn_input = torch.cat([embedded, context], 2)\n",
        "        output, hidden = self.gru(rnn_input, last_hidden)\n",
        "        output = output.squeeze(0)  # (1,B,N) -> (B,N)\n",
        "        context = context.squeeze(0)\n",
        "        output = self.out(torch.cat([output, context], 1))\n",
        "        output = F.log_softmax(output, dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(1)\n",
        "        max_len = src.size(0)\n",
        "        vocab_size = self.decoder.output_size\n",
        "        outputs = Variable(torch.zeros(max_len, batch_size, vocab_size)).cuda()\n",
        "        preds = Variable(torch.zeros(max_len, batch_size)).cuda()\n",
        "        \n",
        "        encoder_output, hidden = self.encoder(src)\n",
        "        hidden = hidden[:self.decoder.n_layers]\n",
        "        output = Variable(trg.data[0, :])  # sos\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden, attn_weights = self.decoder(\n",
        "                    output, hidden, encoder_output)\n",
        "            outputs[t] = output\n",
        "            is_teacher = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.data.max(1)[1]\n",
        "            preds[t] = top1 \n",
        "            output = Variable(trg.data[t] if is_teacher else top1).cuda()\n",
        "        #print(\"output\" )\n",
        "        #print(output.size())    \n",
        "        #print(\"outputs\") \n",
        "        #print(outputs.size())\n",
        "        #print(\"top1\")\n",
        "        #print(top1.size())\n",
        "        #print(\"preds\")\n",
        "        #print( preds.size())\n",
        "        return outputs, preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dckLsJ0Issn",
        "colab_type": "code",
        "outputId": "919bae64-0fb9-4ea7-8e8a-8007f5a59920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "### Testing Encoder part\n",
        "# TODO: put whether GPU is available or not\n",
        "# Device\n",
        "en_size, fr_size = len(english_tokenizer), len(french_tokenizer)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder = Encoder(input_size = en_size, embed_size= 256, hidden_size = 512, n_layers=1, dropout=0.5)\n",
        "\n",
        "encoder.to(device)\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(dataloaders['train'])\n",
        "x, y = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack_sequence\n",
        "xs = x.transpose(0, 1)\n",
        "ys = y.transpose(0, 1)\n",
        "\n",
        "enc_output, enc_hidden = encoder(xs.to(device))\n",
        "print(enc_output.size()) # max_length, batch_size, enc_units"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([23, 64, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAf3am1BLP5m",
        "colab_type": "code",
        "outputId": "11f7c02b-c4fa-4a95-93f5-d1f8629b4c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder = Encoder(input_size = en_size, embed_size= 256, hidden_size = 512, n_layers=1, dropout=0.5)\n",
        "\n",
        "encoder.to(device)\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(dataloaders['train'])\n",
        "x, y = next(it)\n",
        "\n",
        "print(\"Input: \", x.shape)\n",
        "print(\"Output: \", y.shape)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack_sequence\n",
        "xs = x.transpose(0, 1)\n",
        "ys = y.transpose(0, 1)\n",
        "enc_output, enc_hidden = encoder(xs.to(device))\n",
        "\n",
        "print(\"Encoder Output: \", enc_output.shape) # batch_size X max_length X enc_units\n",
        "print(\"Encoder Hidden: \", enc_hidden.shape) # batch_size X enc_units (corresponds to the last state)\n",
        "\n",
        "decoder = Decoder(embed_size= 256, hidden_size = 512, output_size = fr_size, n_layers=1, dropout=0.2)\n",
        "decoder = decoder.to(device)\n",
        "\n",
        "#print(enc_hidden.squeeze(0).shape)\n",
        "\n",
        "dec_hidden = enc_hidden[:1]#.squeeze(0)\n",
        "dec_input = torch.tensor([[french_tokenizer['<sos>']]] * 64)\n",
        "print(\"Decoder Input: \", dec_input.shape)\n",
        "print(\"--------\")\n",
        "\n",
        "for t in range(1, y.size(1)):\n",
        "    # enc_hidden: 1, batch_size, enc_units\n",
        "    # output: max_length, batch_size, enc_units\n",
        "    \n",
        "    predictions, dec_hidden, attn_weights = decoder(dec_input.to(device), \n",
        "                                         dec_hidden.to(device), \n",
        "                                         enc_output.to(device))\n",
        "    \n",
        "    print(\"Prediction: \", predictions.shape)\n",
        "    print(\"Decoder Hidden: \", dec_hidden.shape)\n",
        "    \n",
        "    #loss += loss_function(y[:, t].to(device), predictions.to(device))\n",
        "    \n",
        "    dec_input = y[:, t].unsqueeze(1)\n",
        "    print(dec_input.shape)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:  torch.Size([64, 23])\n",
            "Output:  torch.Size([64, 23])\n",
            "Encoder Output:  torch.Size([23, 64, 512])\n",
            "Encoder Hidden:  torch.Size([2, 64, 512])\n",
            "Decoder Input:  torch.Size([64, 1])\n",
            "--------\n",
            "Prediction:  torch.Size([64, 354])\n",
            "Decoder Hidden:  torch.Size([1, 64, 512])\n",
            "torch.Size([64, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQe3tkzFl6-g",
        "colab_type": "code",
        "outputId": "f803405e-13d6-493d-bd9e-6593881604e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder = Encoder(input_size = en_size, embed_size= 256, hidden_size = 512, n_layers=1, dropout=0.5)\n",
        "\n",
        "encoder.to(device)\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(dataloaders['train'])\n",
        "x, y = next(it)\n",
        "\n",
        "print(\"Input: \", x.shape)\n",
        "print(\"Output: \", y.shape)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack_sequence\n",
        "xs = x.transpose(0, 1)\n",
        "ys = y.transpose(0, 1)\n",
        "enc_output, enc_hidden = encoder(xs.to(device))\n",
        "\n",
        "print(\"Encoder Output: \", enc_output.shape) # batch_size X max_length X enc_units\n",
        "print(\"Encoder Hidden: \", enc_hidden.shape) # batch_size X enc_units (corresponds to the last state)\n",
        "\n",
        "decoder = Decoder(embed_size= 256, hidden_size = 512, output_size = fr_size, n_layers=1, dropout=0.2)\n",
        "decoder = decoder.to(device)\n",
        "\n",
        "#print(enc_hidden.squeeze(0).shape)\n",
        "\n",
        "seq2seq = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "outputs, preds = seq2seq(xs.to(device),ys.to(device))\n",
        "print(\"seq2seq Outputs: \", outputs.shape) # batch_size X max_length X enc_units\n",
        "print(\"seq2seq predictions: \", preds.shape) # batch_size X enc_units (corresponds to the last state)\n",
        "print(\"seq2seq targets: \", ys.shape)\n",
        "print (ys)\n",
        "print (preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input:  torch.Size([64, 23])\n",
            "Output:  torch.Size([64, 23])\n",
            "Encoder Output:  torch.Size([23, 64, 512])\n",
            "Encoder Hidden:  torch.Size([2, 64, 512])\n",
            "seq2seq Outputs:  torch.Size([23, 64, 354])\n",
            "seq2seq predictions:  torch.Size([23, 64])\n",
            "seq2seq targets:  torch.Size([23, 64])\n",
            "tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
            "        [ 12,  37,  36,  ...,   6,  29,  65],\n",
            "        [ 39,   1,  35,  ...,  33, 289,  18],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,   0,   0,   0],\n",
            "        [  0,   0,   0,  ...,   0,   0,   0],\n",
            "        [  0,   0,   0,  ...,   0,   0,   0]])\n",
            "tensor([[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
            "        [306., 159., 278.,  ..., 159., 191., 159.],\n",
            "        [ 88.,  33.,  10.,  ..., 159., 326., 228.],\n",
            "        ...,\n",
            "        [ 61.,  92., 125.,  ..., 327., 242., 125.],\n",
            "        [243., 327., 327.,  ..., 327.,  92., 327.],\n",
            "        [243., 327., 327.,  ..., 327., 327.,  92.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjp-40vxF2Dm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import math\n",
        "import argparse\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.utils import clip_grad_norm\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def train_model(model, model_loss, optimizer, num_epochs, vocab_size, grad_clip, french_tokenizer, english_tokenizer):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_model_wts_loss = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    best_loss = 0.0\n",
        "    best_acc_loss = 0.0\n",
        "    best_loss_acc = 0.0\n",
        "   \n",
        "    valid_acc_history = []\n",
        "    valid_loss_history = []\n",
        "    train_acc_history = []\n",
        "    train_loss_history = []\n",
        "    \n",
        "    total_loss = 0\n",
        "    \n",
        "    model_save_name = 'checkpoint_seq2seq_train_v0.pth'\n",
        "    model_save_loss = 'checkpoint_seq2seq_loss_v0.pth'\n",
        "    path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "    path_loss = F\"/content/gdrive/My Drive/{model_save_loss}\" \n",
        "    \n",
        "    pad = english_tokenizer['<pad>']\n",
        "    \n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                #scheduler.step()\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0.0\n",
        "            total = 0\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "              \n",
        "                inputs = inputs.transpose(0, 1)\n",
        "                labels = labels.transpose(0, 1)\n",
        "                \n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs, preds = model(inputs,labels)\n",
        "                    #_, preds = torch.max(outputs, 1)\n",
        "                    loss = F.nll_loss(outputs[1:].view(-1, vocab_size), labels[1:].contiguous().view(-1), ignore_index=pad)\n",
        "                    \n",
        "                    \n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        clip_grad_norm(model.parameters(), grad_clip)\n",
        "                        optimizer.step()\n",
        "                       \n",
        "\n",
        "                # statistics\n",
        "                #running_loss += loss.data loss.item() / labels.size(0)\n",
        "                \n",
        "                running_loss += loss.data\n",
        "                \n",
        "                preds  = preds.float()\n",
        "                labels  = labels.float()\n",
        "                non_padding = labels.ne(pad)\n",
        "                corrects = preds.eq(labels.data).masked_select(non_padding).sum().item()\n",
        "                running_corrects += corrects\n",
        "                total += non_padding.sum().item()\n",
        "                    \n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase])\n",
        "            epoch_acc = (running_corrects / total) * 100\n",
        "            \n",
        "             \n",
        "      \n",
        "           \n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and epoch_acc >= best_acc:\n",
        "              if epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_acc_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                torch.save(model.state_dict(), path)\n",
        "              elif epoch_acc == best_acc:\n",
        "                if epoch_loss < best_acc_loss: \n",
        "                  best_acc = epoch_acc\n",
        "                  best_acc_loss = epoch_loss\n",
        "                  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                  torch.save(model.state_dict(), path)\n",
        "            if phase == 'valid' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_loss_acc = epoch_acc\n",
        "                best_model_wts_loss = copy.deepcopy(model.state_dict())\n",
        "                torch.save(model.state_dict(), path_loss)\n",
        "            if phase == 'valid':\n",
        "                valid_loss_history.append(epoch_loss)\n",
        "                valid_acc_history.append(epoch_acc)\n",
        "            if phase == 'train':\n",
        "                train_loss_history.append(epoch_loss)\n",
        "                train_acc_history.append(epoch_acc)\n",
        "                \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f} Best val Acc: {:4f} Best_val_Acc_Loss: {:4f} Best_val_Loss: {:4f} Best_val_Loss_acc: {:4f} '.format(phase, epoch_loss, epoch_acc, best_acc, best_acc_loss, best_loss, best_loss_acc))\n",
        "                \n",
        "            \n",
        "\n",
        "        print()\n",
        "        \n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    print('Best val Acc Loss: {:4f}'.format(best_acc_loss))\n",
        "    print('Best val Loss: {:4f}'.format(best_loss))\n",
        "    print('Best val Loss Acc: {:4f}'.format(best_loss_acc))\n",
        "    \n",
        "    \n",
        "    \n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    model_loss.load_state_dict(best_model_wts_loss)\n",
        "    return model, model_loss, train_acc_history, valid_acc_history, train_loss_history, valid_loss_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzXSFzs1g3if",
        "colab_type": "code",
        "outputId": "e1bcf1bb-d750-482c-cedc-d25554efb693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "    hidden_size = 512\n",
        "    embed_size = 256\n",
        "    \n",
        "    epochs=25\n",
        "                   \n",
        "    batch_size=64\n",
        "    \n",
        "    lr=0.001\n",
        "    \n",
        "    grad_clip=5.0\n",
        "    \n",
        "                  \n",
        "    \n",
        "    assert torch.cuda.is_available()\n",
        "\n",
        "    print(\"[!] preparing dataset...\")\n",
        "     \n",
        "    en_size, fr_size = len(english_tokenizer), len(french_tokenizer)\n",
        "    print(\"[TRAIN]:%d (dataset:%d)\\t[TEST]:%d (dataset:%d)\"\n",
        "          % (len(dataloaders['train']), len(dataloaders['train'].dataset),\n",
        "             len(dataloaders['train']), len(dataloaders['train'].dataset)))\n",
        "    print(\"[fr_vocab]:%d [en_vocab]:%d\" % (fr_size, en_size))\n",
        "\n",
        "    print(\"[!] Instantiating models...\")\n",
        "    encoder = Encoder(en_size, embed_size, hidden_size, n_layers=2, dropout=0.5)\n",
        "    decoder = Decoder(embed_size, hidden_size, fr_size, n_layers=1, dropout=0.5)\n",
        "    seq2seq = Seq2Seq(encoder, decoder).to(device)\n",
        "    seq2seq_loss = Seq2Seq(encoder, decoder).to(device)\n",
        "    optimizer = optim.Adam(seq2seq.parameters(), lr=lr)\n",
        "    print(seq2seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[!] preparing dataset...\n",
            "[TRAIN]:1724 (dataset:110288)\t[TEST]:1724 (dataset:110288)\n",
            "[fr_vocab]:354 [en_vocab]:227\n",
            "[!] Instantiating models...\n",
            "Seq2Seq(\n",
            "  (encoder): Encoder(\n",
            "    (embed): Embedding(227, 256)\n",
            "    (gru): GRU(256, 512, num_layers=2, dropout=0.5, bidirectional=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (embed): Embedding(354, 256)\n",
            "    (dropout): Dropout(p=0.5, inplace)\n",
            "    (attention): Attention(\n",
            "      (attn): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    )\n",
            "    (gru): GRU(768, 512, dropout=0.5)\n",
            "    (out): Linear(in_features=1024, out_features=354, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcpdbLomyGPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_loss = Seq2Seq(encoder, decoder).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc729qnxyAMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Seq2Seq(encoder, decoder).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-3-wQx6hHwM",
        "colab_type": "code",
        "outputId": "d3c376c5-fb9f-4fbe-826c-ed2281b04101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2366
        }
      },
      "source": [
        "model, model_loss, train_hist, valid_hist, train_loss_history, valid_loss_history = train_model(seq2seq, seq2seq_loss, optimizer, epochs+1, fr_size, grad_clip, french_tokenizer, english_tokenizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/26\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 1.0313 Acc: 66.1489 Best val Acc: 0.000000 Best_val_Acc_Loss: 0.000000 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.4562 Acc: 80.5563 Best val Acc: 80.556274 Best_val_Acc_Loss: 0.456208 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 2/26\n",
            "----------\n",
            "train Loss: 0.3426 Acc: 82.8409 Best val Acc: 80.556274 Best_val_Acc_Loss: 0.456208 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.2488 Acc: 85.3792 Best val Acc: 85.379174 Best_val_Acc_Loss: 0.248849 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 3/26\n",
            "----------\n",
            "train Loss: 0.1795 Acc: 87.7080 Best val Acc: 85.379174 Best_val_Acc_Loss: 0.248849 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.1311 Acc: 89.1625 Best val Acc: 89.162547 Best_val_Acc_Loss: 0.131061 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 4/26\n",
            "----------\n",
            "train Loss: 0.1182 Acc: 89.6121 Best val Acc: 89.162547 Best_val_Acc_Loss: 0.131061 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.1002 Acc: 90.0936 Best val Acc: 90.093557 Best_val_Acc_Loss: 0.100157 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 5/26\n",
            "----------\n",
            "train Loss: 0.0892 Acc: 90.6683 Best val Acc: 90.093557 Best_val_Acc_Loss: 0.100157 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0760 Acc: 91.0951 Best val Acc: 91.095053 Best_val_Acc_Loss: 0.075963 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 6/26\n",
            "----------\n",
            "train Loss: 0.0727 Acc: 91.1558 Best val Acc: 91.095053 Best_val_Acc_Loss: 0.075963 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0747 Acc: 91.1189 Best val Acc: 91.118886 Best_val_Acc_Loss: 0.074716 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 7/26\n",
            "----------\n",
            "train Loss: 0.0676 Acc: 91.3300 Best val Acc: 91.118886 Best_val_Acc_Loss: 0.074716 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0680 Acc: 91.3800 Best val Acc: 91.380036 Best_val_Acc_Loss: 0.068036 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 8/26\n",
            "----------\n",
            "train Loss: 0.0592 Acc: 91.5523 Best val Acc: 91.380036 Best_val_Acc_Loss: 0.068036 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0603 Acc: 91.5327 Best val Acc: 91.532669 Best_val_Acc_Loss: 0.060276 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 9/26\n",
            "----------\n",
            "train Loss: 0.0585 Acc: 91.5980 Best val Acc: 91.532669 Best_val_Acc_Loss: 0.060276 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0527 Acc: 91.7827 Best val Acc: 91.782663 Best_val_Acc_Loss: 0.052743 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 10/26\n",
            "----------\n",
            "train Loss: 0.0540 Acc: 91.7338 Best val Acc: 91.782663 Best_val_Acc_Loss: 0.052743 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0579 Acc: 91.6103 Best val Acc: 91.782663 Best_val_Acc_Loss: 0.052743 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 11/26\n",
            "----------\n",
            "train Loss: 0.0531 Acc: 91.7595 Best val Acc: 91.782663 Best_val_Acc_Loss: 0.052743 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0533 Acc: 91.7918 Best val Acc: 91.791790 Best_val_Acc_Loss: 0.053344 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 12/26\n",
            "----------\n",
            "train Loss: 0.0500 Acc: 91.8393 Best val Acc: 91.791790 Best_val_Acc_Loss: 0.053344 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0495 Acc: 91.9028 Best val Acc: 91.902842 Best_val_Acc_Loss: 0.049538 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 13/26\n",
            "----------\n",
            "train Loss: 0.0498 Acc: 91.8500 Best val Acc: 91.902842 Best_val_Acc_Loss: 0.049538 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0476 Acc: 91.9566 Best val Acc: 91.956593 Best_val_Acc_Loss: 0.047640 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 14/26\n",
            "----------\n",
            "train Loss: 0.0501 Acc: 91.8593 Best val Acc: 91.956593 Best_val_Acc_Loss: 0.047640 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0511 Acc: 91.8785 Best val Acc: 91.956593 Best_val_Acc_Loss: 0.047640 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 15/26\n",
            "----------\n",
            "train Loss: 0.0478 Acc: 91.8964 Best val Acc: 91.956593 Best_val_Acc_Loss: 0.047640 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0506 Acc: 91.9267 Best val Acc: 91.956593 Best_val_Acc_Loss: 0.047640 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 16/26\n",
            "----------\n",
            "train Loss: 0.0469 Acc: 91.9278 Best val Acc: 91.956593 Best_val_Acc_Loss: 0.047640 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0600 Acc: 91.6762 Best val Acc: 91.956593 Best_val_Acc_Loss: 0.047640 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 17/26\n",
            "----------\n",
            "train Loss: 0.0465 Acc: 91.9399 Best val Acc: 91.956593 Best_val_Acc_Loss: 0.047640 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0616 Acc: 91.6676 Best val Acc: 91.956593 Best_val_Acc_Loss: 0.047640 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 18/26\n",
            "----------\n",
            "train Loss: 0.0459 Acc: 91.9507 Best val Acc: 91.956593 Best_val_Acc_Loss: 0.047640 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0479 Acc: 91.9551 Best val Acc: 91.956593 Best_val_Acc_Loss: 0.047640 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 19/26\n",
            "----------\n",
            "train Loss: 0.0455 Acc: 91.9569 Best val Acc: 91.956593 Best_val_Acc_Loss: 0.047640 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0481 Acc: 91.9789 Best val Acc: 91.978905 Best_val_Acc_Loss: 0.048059 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 20/26\n",
            "----------\n",
            "train Loss: 0.0462 Acc: 91.9550 Best val Acc: 91.978905 Best_val_Acc_Loss: 0.048059 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0492 Acc: 91.9617 Best val Acc: 91.978905 Best_val_Acc_Loss: 0.048059 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 21/26\n",
            "----------\n",
            "train Loss: 0.0472 Acc: 91.9241 Best val Acc: 91.978905 Best_val_Acc_Loss: 0.048059 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0453 Acc: 92.0129 Best val Acc: 92.012880 Best_val_Acc_Loss: 0.045292 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 22/26\n",
            "----------\n",
            "train Loss: 0.0449 Acc: 91.9796 Best val Acc: 92.012880 Best_val_Acc_Loss: 0.045292 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0514 Acc: 91.8826 Best val Acc: 92.012880 Best_val_Acc_Loss: 0.045292 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 23/26\n",
            "----------\n",
            "train Loss: 0.0428 Acc: 92.0228 Best val Acc: 92.012880 Best_val_Acc_Loss: 0.045292 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0485 Acc: 91.9409 Best val Acc: 92.012880 Best_val_Acc_Loss: 0.045292 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 24/26\n",
            "----------\n",
            "train Loss: 0.0445 Acc: 91.9921 Best val Acc: 92.012880 Best_val_Acc_Loss: 0.045292 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0482 Acc: 91.9642 Best val Acc: 92.012880 Best_val_Acc_Loss: 0.045292 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 25/26\n",
            "----------\n",
            "train Loss: 0.0446 Acc: 92.0054 Best val Acc: 92.012880 Best_val_Acc_Loss: 0.045292 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0527 Acc: 91.9054 Best val Acc: 92.012880 Best_val_Acc_Loss: 0.045292 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Epoch 26/26\n",
            "----------\n",
            "train Loss: 0.0422 Acc: 92.0324 Best val Acc: 92.012880 Best_val_Acc_Loss: 0.045292 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "valid Loss: 0.0497 Acc: 91.9591 Best val Acc: 92.012880 Best_val_Acc_Loss: 0.045292 Best_val_Loss: 0.000000 Best_val_Loss_acc: 0.000000 \n",
            "\n",
            "Training complete in 213m 2s\n",
            "Best val Acc: 92.012880\n",
            "Best val Acc Loss: 0.045292\n",
            "Best val Loss: 0.000000\n",
            "Best val Loss Acc: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SRXe_h00uQf",
        "colab_type": "code",
        "outputId": "14f01ecb-f668-4f13-92e5-43ee7582bae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embed): Embedding(227, 256)\n",
              "    (gru): GRU(256, 512, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embed): Embedding(354, 256)\n",
              "    (dropout): Dropout(p=0.5, inplace)\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    )\n",
              "    (gru): GRU(768, 512, dropout=0.5)\n",
              "    (out): Linear(in_features=1024, out_features=354, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG3YyCe_7FbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_valid(model, vocab_size, french_tokenizer, english_tokenizer):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    accuracy = 0\n",
        "    test_error = 0\n",
        "    test_accuracy = 0 \n",
        "    pad = english_tokenizer['<pad>']\n",
        "    \n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "    \n",
        "    for src, trg in dataloaders['valid']:\n",
        "        src = src.transpose(0, 1)\n",
        "        trg = trg.transpose(0, 1)\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        with torch.no_grad():\n",
        "            output, pred = model(src, trg)\n",
        "         \n",
        "        loss = F.nll_loss(output[1:].view(-1, vocab_size),trg[1:].contiguous().view(-1), ignore_index=pad)\n",
        "        total_loss += loss.data\n",
        "        \n",
        "       \n",
        "        pred = pred.float()\n",
        "        trg  = trg.float()\n",
        "        non_padding = trg.ne(pad)\n",
        "        corrects = pred.eq(trg.data).masked_select(non_padding).sum().item()\n",
        "        accuracy += corrects\n",
        "        total += non_padding.sum().item()\n",
        "        #print(accuracy)\n",
        "        \n",
        "    test_error = total_loss / len(dataloaders['valid'])\n",
        "    test_accuracy = ( accuracy / total  ) * 100\n",
        "    \n",
        "    \n",
        "    return test_error, test_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqjQPk8VyjqS",
        "colab_type": "code",
        "outputId": "46caacb6-f11c-428d-b0ca-bb414b669bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5786
        }
      },
      "source": [
        "for name,param in model.named_parameters():\n",
        "  print(name)\n",
        "  print(param.data)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder.embed.weight\n",
            "tensor([[-1.1652,  0.0564,  1.7151,  ..., -1.1676,  0.8155,  1.0169],\n",
            "        [ 0.2293,  0.2063,  0.5326,  ...,  1.5195,  1.4301,  1.0686],\n",
            "        [ 1.5813, -1.3332,  1.2815,  ..., -1.4151,  0.0031, -0.5095],\n",
            "        ...,\n",
            "        [ 1.0775,  0.0871, -0.1687,  ..., -1.1340,  0.0905,  1.1670],\n",
            "        [-0.1030, -0.5513,  0.5572,  ...,  1.3435, -0.7266, -0.0171],\n",
            "        [ 0.7430,  1.8899, -1.0459,  ..., -0.5868,  0.0818,  0.9288]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_ih_l0\n",
            "tensor([[ 0.0200,  0.0399, -0.0164,  ...,  0.0404, -0.0421,  0.0101],\n",
            "        [ 0.0426,  0.0325, -0.0166,  ..., -0.0163, -0.0030, -0.0329],\n",
            "        [ 0.0096,  0.0336,  0.0145,  ...,  0.0098,  0.0014,  0.0284],\n",
            "        ...,\n",
            "        [ 0.0395, -0.0059, -0.0254,  ..., -0.0416,  0.0345, -0.0318],\n",
            "        [-0.0237,  0.0435,  0.0067,  ..., -0.0126, -0.0105, -0.0006],\n",
            "        [ 0.0227,  0.0251, -0.0289,  ...,  0.0348,  0.0310, -0.0030]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_hh_l0\n",
            "tensor([[ 0.0408, -0.0071,  0.0115,  ...,  0.0158, -0.0173, -0.0103],\n",
            "        [ 0.0129, -0.0273, -0.0282,  ...,  0.0193, -0.0288,  0.0237],\n",
            "        [ 0.0441, -0.0324, -0.0240,  ..., -0.0271, -0.0189, -0.0325],\n",
            "        ...,\n",
            "        [ 0.0109,  0.0040, -0.0268,  ...,  0.0350, -0.0318,  0.0062],\n",
            "        [-0.0222,  0.0432, -0.0346,  ...,  0.0268, -0.0028,  0.0393],\n",
            "        [-0.0021,  0.0131, -0.0174,  ..., -0.0402, -0.0399, -0.0377]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_ih_l0\n",
            "tensor([-0.0010,  0.0361,  0.0225,  ..., -0.0306, -0.0434, -0.0420],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_hh_l0\n",
            "tensor([-0.0325,  0.0005, -0.0426,  ...,  0.0421,  0.0041,  0.0384],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_ih_l0_reverse\n",
            "tensor([[ 0.0281, -0.0239,  0.0432,  ...,  0.0355, -0.0376,  0.0359],\n",
            "        [-0.0387,  0.0112, -0.0322,  ...,  0.0439, -0.0400,  0.0131],\n",
            "        [-0.0304,  0.0082, -0.0191,  ...,  0.0391,  0.0007,  0.0142],\n",
            "        ...,\n",
            "        [-0.0045,  0.0237,  0.0224,  ...,  0.0424,  0.0149,  0.0148],\n",
            "        [-0.0084, -0.0304, -0.0159,  ...,  0.0016, -0.0353, -0.0395],\n",
            "        [ 0.0412,  0.0327,  0.0198,  ...,  0.0295,  0.0201, -0.0360]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_hh_l0_reverse\n",
            "tensor([[-0.0130, -0.0090, -0.0400,  ..., -0.0188, -0.0042, -0.0186],\n",
            "        [-0.0286, -0.0418, -0.0398,  ..., -0.0207, -0.0265,  0.0088],\n",
            "        [ 0.0121, -0.0164, -0.0062,  ...,  0.0193,  0.0085,  0.0311],\n",
            "        ...,\n",
            "        [ 0.0414,  0.0197, -0.0214,  ...,  0.0055,  0.0112,  0.0011],\n",
            "        [ 0.0109, -0.0188, -0.0090,  ..., -0.0080,  0.0347,  0.0283],\n",
            "        [-0.0363,  0.0243, -0.0123,  ...,  0.0316, -0.0325,  0.0406]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_ih_l0_reverse\n",
            "tensor([ 0.0125, -0.0398, -0.0323,  ..., -0.0310, -0.0268,  0.0413],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_hh_l0_reverse\n",
            "tensor([-0.0116, -0.0376, -0.0398,  ...,  0.0256,  0.0092,  0.0158],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_ih_l1\n",
            "tensor([[ 0.0158,  0.0221,  0.0433,  ...,  0.0291, -0.0372,  0.0333],\n",
            "        [-0.0025, -0.0040,  0.0043,  ...,  0.0162, -0.0072,  0.0097],\n",
            "        [-0.0064,  0.0279, -0.0319,  ..., -0.0187, -0.0240, -0.0259],\n",
            "        ...,\n",
            "        [ 0.0375,  0.0283, -0.0120,  ..., -0.0164,  0.0157,  0.0242],\n",
            "        [ 0.0267,  0.0010,  0.0284,  ..., -0.0265, -0.0232, -0.0031],\n",
            "        [ 0.0194,  0.0234, -0.0266,  ..., -0.0408,  0.0296,  0.0425]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_hh_l1\n",
            "tensor([[ 0.0085,  0.0032, -0.0258,  ..., -0.0075, -0.0391,  0.0079],\n",
            "        [ 0.0336, -0.0107, -0.0012,  ...,  0.0278,  0.0342, -0.0241],\n",
            "        [-0.0211,  0.0300,  0.0409,  ..., -0.0088, -0.0041, -0.0003],\n",
            "        ...,\n",
            "        [-0.0234,  0.0360, -0.0165,  ..., -0.0274,  0.0316,  0.0123],\n",
            "        [-0.0176, -0.0140,  0.0103,  ...,  0.0425,  0.0108,  0.0219],\n",
            "        [-0.0310, -0.0010, -0.0138,  ..., -0.0237, -0.0212, -0.0352]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_ih_l1\n",
            "tensor([ 0.0179,  0.0002,  0.0412,  ..., -0.0318, -0.0207, -0.0274],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_hh_l1\n",
            "tensor([-0.0326, -0.0299,  0.0258,  ..., -0.0353, -0.0307,  0.0412],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_ih_l1_reverse\n",
            "tensor([[ 0.0221,  0.0344, -0.0147,  ..., -0.0064,  0.0417,  0.0131],\n",
            "        [ 0.0340,  0.0048,  0.0265,  ...,  0.0388,  0.0334,  0.0187],\n",
            "        [-0.0424, -0.0098, -0.0166,  ...,  0.0186,  0.0260, -0.0399],\n",
            "        ...,\n",
            "        [ 0.0397,  0.0119, -0.0073,  ...,  0.0410, -0.0088,  0.0392],\n",
            "        [-0.0408, -0.0384, -0.0260,  ...,  0.0293, -0.0271, -0.0065],\n",
            "        [-0.0034, -0.0400,  0.0246,  ...,  0.0039,  0.0253,  0.0023]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_hh_l1_reverse\n",
            "tensor([[ 0.0109,  0.0338,  0.0040,  ...,  0.0441, -0.0087,  0.0211],\n",
            "        [ 0.0154, -0.0202, -0.0298,  ...,  0.0077,  0.0021, -0.0107],\n",
            "        [ 0.0131,  0.0400,  0.0151,  ..., -0.0086, -0.0186,  0.0089],\n",
            "        ...,\n",
            "        [-0.0146,  0.0159,  0.0150,  ...,  0.0400, -0.0047, -0.0074],\n",
            "        [ 0.0173,  0.0264,  0.0217,  ..., -0.0142, -0.0166,  0.0219],\n",
            "        [-0.0269,  0.0183,  0.0293,  ..., -0.0302, -0.0379, -0.0165]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_ih_l1_reverse\n",
            "tensor([ 0.0365,  0.0336,  0.0080,  ...,  0.0122, -0.0209, -0.0358],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_hh_l1_reverse\n",
            "tensor([ 0.0341, -0.0024,  0.0207,  ..., -0.0400, -0.0079, -0.0319],\n",
            "       device='cuda:0')\n",
            "decoder.embed.weight\n",
            "tensor([[-0.2745,  0.0698,  0.7196,  ..., -0.1048, -0.2250,  0.0942],\n",
            "        [ 1.0533, -0.8794, -1.1407,  ..., -0.8550,  0.4688, -0.1683],\n",
            "        [-0.5542,  1.4317, -0.5416,  ..., -0.3400, -0.2567,  1.3658],\n",
            "        ...,\n",
            "        [-0.3792, -0.5457, -0.3952,  ...,  0.7270, -1.3885, -1.1543],\n",
            "        [-0.8706, -1.0070, -0.6268,  ...,  0.8202,  0.4246,  0.4589],\n",
            "        [-1.0375,  0.5961,  1.1624,  ...,  1.1585, -0.8944, -0.1638]],\n",
            "       device='cuda:0')\n",
            "decoder.attention.v\n",
            "tensor([ 0.0099, -0.0048, -0.0055, -0.0188,  0.0353,  0.0006,  0.0048, -0.0208,\n",
            "         0.0184, -0.0029, -0.0269,  0.0080, -0.0128, -0.0404, -0.0166,  0.0139,\n",
            "         0.0112, -0.0167,  0.0226, -0.0312, -0.0157, -0.0252, -0.0149, -0.0304,\n",
            "        -0.0243,  0.0171,  0.0306,  0.0092,  0.0041, -0.0145,  0.0349,  0.0198,\n",
            "         0.0377, -0.0369, -0.0257,  0.0352, -0.0149, -0.0432,  0.0197,  0.0361,\n",
            "         0.0347, -0.0296, -0.0395, -0.0400, -0.0256,  0.0316,  0.0002,  0.0235,\n",
            "         0.0154, -0.0258, -0.0344,  0.0157, -0.0423, -0.0257,  0.0210,  0.0064,\n",
            "        -0.0027,  0.0194,  0.0148, -0.0021,  0.0422, -0.0100, -0.0052,  0.0133,\n",
            "        -0.0270,  0.0188,  0.0197,  0.0277,  0.0226,  0.0091, -0.0240,  0.0396,\n",
            "        -0.0383,  0.0181,  0.0374, -0.0292, -0.0274, -0.0408,  0.0123, -0.0300,\n",
            "        -0.0327,  0.0162, -0.0004, -0.0437, -0.0102,  0.0209, -0.0438, -0.0358,\n",
            "         0.0040,  0.0088, -0.0013,  0.0287, -0.0023,  0.0378, -0.0330, -0.0121,\n",
            "        -0.0261, -0.0267, -0.0028,  0.0012,  0.0019,  0.0276,  0.0134, -0.0057,\n",
            "         0.0065, -0.0435,  0.0009,  0.0335, -0.0042, -0.0332,  0.0075,  0.0013,\n",
            "        -0.0352, -0.0169, -0.0166,  0.0307, -0.0325, -0.0197, -0.0349, -0.0161,\n",
            "         0.0153,  0.0084, -0.0080, -0.0104,  0.0355,  0.0173,  0.0318, -0.0004,\n",
            "        -0.0024,  0.0273,  0.0411, -0.0216, -0.0265,  0.0364,  0.0034, -0.0196,\n",
            "        -0.0017,  0.0122,  0.0361,  0.0266,  0.0284, -0.0323, -0.0249, -0.0138,\n",
            "        -0.0139,  0.0100,  0.0041, -0.0365, -0.0392, -0.0343, -0.0164,  0.0152,\n",
            "         0.0311,  0.0137,  0.0331, -0.0358,  0.0426, -0.0111,  0.0114,  0.0125,\n",
            "         0.0253,  0.0039, -0.0239, -0.0375,  0.0212, -0.0270, -0.0280, -0.0319,\n",
            "         0.0159, -0.0140, -0.0428,  0.0324,  0.0317,  0.0313,  0.0124,  0.0064,\n",
            "        -0.0004, -0.0408,  0.0217, -0.0139, -0.0020, -0.0058, -0.0169, -0.0227,\n",
            "        -0.0301,  0.0169,  0.0127, -0.0387,  0.0347,  0.0415, -0.0397, -0.0349,\n",
            "        -0.0077,  0.0234,  0.0258, -0.0353, -0.0080, -0.0359,  0.0140,  0.0025,\n",
            "        -0.0203, -0.0311,  0.0390, -0.0395,  0.0029,  0.0055,  0.0330, -0.0244,\n",
            "         0.0303, -0.0385,  0.0061, -0.0353,  0.0160,  0.0435, -0.0298,  0.0327,\n",
            "        -0.0441,  0.0266,  0.0285,  0.0121, -0.0180,  0.0030,  0.0424, -0.0343,\n",
            "         0.0199,  0.0269,  0.0234,  0.0001,  0.0207,  0.0407, -0.0116,  0.0387,\n",
            "        -0.0270, -0.0426,  0.0127,  0.0066,  0.0087, -0.0153, -0.0134, -0.0164,\n",
            "        -0.0246,  0.0276,  0.0354, -0.0115, -0.0015, -0.0424, -0.0070,  0.0252,\n",
            "         0.0081, -0.0277, -0.0028, -0.0270,  0.0216,  0.0060, -0.0417, -0.0170,\n",
            "         0.0364, -0.0108,  0.0207, -0.0297,  0.0104, -0.0095, -0.0225, -0.0315,\n",
            "         0.0326,  0.0161, -0.0315, -0.0441, -0.0133,  0.0376, -0.0371, -0.0088,\n",
            "         0.0435, -0.0065,  0.0335,  0.0237, -0.0088,  0.0378, -0.0413,  0.0202,\n",
            "         0.0392,  0.0280,  0.0392, -0.0233, -0.0006, -0.0149, -0.0123, -0.0255,\n",
            "        -0.0150, -0.0221, -0.0440,  0.0270,  0.0383,  0.0379,  0.0401,  0.0177,\n",
            "        -0.0333, -0.0129, -0.0435, -0.0221, -0.0205, -0.0294, -0.0026, -0.0186,\n",
            "         0.0171,  0.0212, -0.0300, -0.0329,  0.0123,  0.0020, -0.0137, -0.0147,\n",
            "         0.0061,  0.0244,  0.0120,  0.0337, -0.0256, -0.0138, -0.0387,  0.0283,\n",
            "        -0.0404, -0.0197, -0.0015, -0.0084,  0.0301, -0.0303, -0.0111, -0.0103,\n",
            "         0.0355,  0.0232,  0.0016,  0.0318,  0.0078, -0.0298,  0.0090,  0.0133,\n",
            "         0.0146,  0.0161, -0.0060, -0.0316, -0.0263, -0.0319, -0.0304, -0.0209,\n",
            "         0.0292,  0.0302,  0.0070, -0.0379,  0.0219,  0.0328,  0.0157,  0.0225,\n",
            "        -0.0179, -0.0104, -0.0420,  0.0241,  0.0314, -0.0251,  0.0173, -0.0203,\n",
            "        -0.0123,  0.0181,  0.0124,  0.0056, -0.0005,  0.0333, -0.0149,  0.0211,\n",
            "        -0.0313, -0.0136,  0.0176,  0.0168,  0.0123,  0.0142, -0.0108,  0.0317,\n",
            "         0.0140, -0.0421,  0.0094,  0.0038,  0.0148,  0.0427, -0.0182,  0.0424,\n",
            "         0.0306,  0.0040,  0.0287,  0.0187,  0.0103, -0.0122, -0.0360, -0.0063,\n",
            "        -0.0088, -0.0343,  0.0071,  0.0223,  0.0103, -0.0077, -0.0112,  0.0077,\n",
            "        -0.0065,  0.0034,  0.0078, -0.0428, -0.0174,  0.0406,  0.0290,  0.0053,\n",
            "         0.0439, -0.0056,  0.0313,  0.0155, -0.0017,  0.0174,  0.0221, -0.0354,\n",
            "        -0.0238,  0.0061,  0.0124, -0.0051,  0.0303,  0.0222,  0.0004,  0.0015,\n",
            "         0.0325,  0.0313,  0.0090,  0.0326, -0.0284, -0.0387,  0.0116, -0.0182,\n",
            "        -0.0164, -0.0362,  0.0306, -0.0349,  0.0122, -0.0040, -0.0300, -0.0402,\n",
            "        -0.0100, -0.0012,  0.0122,  0.0004, -0.0361, -0.0062,  0.0366,  0.0396,\n",
            "        -0.0157, -0.0283,  0.0125,  0.0327,  0.0191, -0.0275,  0.0138, -0.0185,\n",
            "         0.0438,  0.0267,  0.0258,  0.0155,  0.0171,  0.0291, -0.0040, -0.0184,\n",
            "        -0.0019,  0.0329, -0.0183,  0.0094,  0.0348,  0.0126, -0.0287,  0.0230,\n",
            "         0.0060, -0.0220, -0.0289, -0.0217, -0.0101,  0.0180, -0.0224,  0.0344,\n",
            "         0.0373, -0.0304, -0.0107,  0.0339,  0.0278,  0.0333, -0.0124, -0.0262,\n",
            "         0.0426,  0.0344,  0.0408,  0.0238, -0.0173,  0.0393,  0.0259, -0.0169,\n",
            "         0.0362,  0.0273,  0.0067,  0.0306, -0.0236, -0.0249,  0.0220, -0.0348,\n",
            "         0.0096, -0.0151,  0.0426,  0.0338,  0.0177, -0.0264,  0.0131, -0.0332],\n",
            "       device='cuda:0')\n",
            "decoder.attention.attn.weight\n",
            "tensor([[-0.0103,  0.0287, -0.0144,  ...,  0.0093, -0.0230, -0.0086],\n",
            "        [ 0.0160,  0.0160,  0.0021,  ..., -0.0247, -0.0060,  0.0310],\n",
            "        [ 0.0171,  0.0172,  0.0275,  ...,  0.0298,  0.0089, -0.0149],\n",
            "        ...,\n",
            "        [-0.0228,  0.0251, -0.0178,  ..., -0.0074, -0.0219, -0.0085],\n",
            "        [ 0.0069, -0.0242, -0.0115,  ..., -0.0058,  0.0227, -0.0190],\n",
            "        [ 0.0079,  0.0106, -0.0149,  ...,  0.0060, -0.0200, -0.0110]],\n",
            "       device='cuda:0')\n",
            "decoder.attention.attn.bias\n",
            "tensor([-0.0108,  0.0134, -0.0189,  0.0208, -0.0193, -0.0026, -0.0181,  0.0077,\n",
            "         0.0044, -0.0143, -0.0199,  0.0032,  0.0178,  0.0012, -0.0111, -0.0086,\n",
            "         0.0095,  0.0024, -0.0098, -0.0012, -0.0252,  0.0116, -0.0085, -0.0246,\n",
            "         0.0032,  0.0005,  0.0057, -0.0298, -0.0258,  0.0135,  0.0095, -0.0242,\n",
            "        -0.0139, -0.0124,  0.0037, -0.0028,  0.0167,  0.0012, -0.0033, -0.0143,\n",
            "         0.0251,  0.0305,  0.0051, -0.0173,  0.0130, -0.0189, -0.0188, -0.0002,\n",
            "         0.0234,  0.0207, -0.0234,  0.0081, -0.0305,  0.0195, -0.0268,  0.0102,\n",
            "        -0.0236,  0.0157,  0.0064,  0.0073,  0.0121, -0.0303,  0.0250,  0.0080,\n",
            "         0.0005, -0.0028, -0.0287, -0.0186,  0.0040,  0.0039, -0.0080, -0.0091,\n",
            "         0.0184,  0.0260, -0.0055,  0.0110, -0.0008, -0.0312, -0.0027, -0.0261,\n",
            "        -0.0096,  0.0170,  0.0044,  0.0234, -0.0104,  0.0141, -0.0096,  0.0187,\n",
            "         0.0241,  0.0140, -0.0230,  0.0053,  0.0215,  0.0102,  0.0246,  0.0107,\n",
            "         0.0184,  0.0150,  0.0092,  0.0048, -0.0103, -0.0306,  0.0236, -0.0064,\n",
            "        -0.0070,  0.0209, -0.0102, -0.0281,  0.0084, -0.0225, -0.0187,  0.0223,\n",
            "        -0.0137,  0.0087, -0.0005, -0.0139, -0.0127,  0.0275, -0.0226,  0.0222,\n",
            "        -0.0008, -0.0122,  0.0038,  0.0055,  0.0222, -0.0060, -0.0164,  0.0234,\n",
            "        -0.0087, -0.0158,  0.0033,  0.0307,  0.0109,  0.0181,  0.0006,  0.0132,\n",
            "         0.0202,  0.0106, -0.0224, -0.0050,  0.0236,  0.0302,  0.0055, -0.0186,\n",
            "        -0.0288, -0.0011, -0.0193,  0.0032,  0.0140, -0.0166,  0.0023,  0.0254,\n",
            "         0.0057,  0.0190, -0.0254,  0.0287,  0.0309, -0.0040, -0.0246,  0.0051,\n",
            "        -0.0240, -0.0166, -0.0062,  0.0298, -0.0120,  0.0149,  0.0305, -0.0085,\n",
            "        -0.0070,  0.0184,  0.0040,  0.0278,  0.0175, -0.0042, -0.0139,  0.0046,\n",
            "        -0.0199, -0.0219,  0.0196, -0.0263,  0.0166,  0.0174,  0.0213, -0.0205,\n",
            "        -0.0048,  0.0119,  0.0250,  0.0065, -0.0174, -0.0232, -0.0171,  0.0233,\n",
            "         0.0203,  0.0057,  0.0282, -0.0108,  0.0280, -0.0232, -0.0180, -0.0158,\n",
            "         0.0030, -0.0264,  0.0211,  0.0022,  0.0164, -0.0106, -0.0219,  0.0026,\n",
            "        -0.0309,  0.0223,  0.0092, -0.0301,  0.0168, -0.0242,  0.0159,  0.0306,\n",
            "        -0.0074,  0.0019,  0.0215,  0.0007, -0.0290,  0.0273,  0.0299,  0.0248,\n",
            "        -0.0296,  0.0253,  0.0168,  0.0209,  0.0230, -0.0156,  0.0044,  0.0067,\n",
            "        -0.0106,  0.0204, -0.0237,  0.0070,  0.0225, -0.0150,  0.0074,  0.0101,\n",
            "        -0.0122,  0.0223, -0.0309,  0.0124, -0.0169,  0.0049,  0.0035, -0.0258,\n",
            "        -0.0118, -0.0224,  0.0207,  0.0298,  0.0278,  0.0009, -0.0239, -0.0150,\n",
            "        -0.0053, -0.0007,  0.0288, -0.0191, -0.0268,  0.0077, -0.0213,  0.0271,\n",
            "        -0.0009,  0.0094,  0.0027, -0.0140,  0.0092,  0.0133,  0.0288, -0.0260,\n",
            "        -0.0298,  0.0243,  0.0144, -0.0245,  0.0207, -0.0131,  0.0009, -0.0261,\n",
            "         0.0114, -0.0075, -0.0250,  0.0100, -0.0035,  0.0061, -0.0084, -0.0276,\n",
            "        -0.0222,  0.0307,  0.0177, -0.0020,  0.0052,  0.0239,  0.0027, -0.0173,\n",
            "        -0.0280,  0.0169,  0.0015, -0.0140, -0.0021,  0.0304,  0.0179, -0.0236,\n",
            "         0.0297,  0.0307,  0.0034, -0.0021, -0.0186,  0.0196,  0.0139,  0.0191,\n",
            "         0.0304,  0.0167, -0.0209, -0.0253,  0.0084, -0.0031,  0.0106,  0.0288,\n",
            "        -0.0187, -0.0073,  0.0124, -0.0149, -0.0258,  0.0158,  0.0202,  0.0233,\n",
            "        -0.0152, -0.0260,  0.0233,  0.0237, -0.0305, -0.0213, -0.0029, -0.0045,\n",
            "        -0.0120,  0.0046, -0.0063, -0.0198, -0.0263,  0.0043,  0.0103,  0.0190,\n",
            "         0.0302, -0.0291,  0.0104,  0.0268, -0.0141, -0.0068, -0.0166, -0.0237,\n",
            "         0.0124,  0.0194,  0.0185,  0.0268,  0.0256,  0.0164, -0.0156, -0.0110,\n",
            "         0.0155, -0.0169,  0.0192,  0.0015,  0.0255, -0.0132,  0.0038, -0.0213,\n",
            "         0.0075,  0.0157,  0.0311, -0.0279,  0.0079,  0.0258, -0.0090, -0.0081,\n",
            "         0.0225,  0.0126, -0.0188,  0.0177,  0.0070,  0.0310, -0.0049,  0.0200,\n",
            "        -0.0081,  0.0173, -0.0288,  0.0235, -0.0081,  0.0023, -0.0266,  0.0191,\n",
            "        -0.0132,  0.0204, -0.0195,  0.0028,  0.0101,  0.0222, -0.0114, -0.0148,\n",
            "        -0.0038,  0.0191, -0.0035,  0.0256,  0.0139,  0.0002, -0.0212,  0.0087,\n",
            "        -0.0116,  0.0096,  0.0080, -0.0271,  0.0067, -0.0094,  0.0099, -0.0067,\n",
            "        -0.0123,  0.0127,  0.0034, -0.0009,  0.0239,  0.0013,  0.0158,  0.0244,\n",
            "        -0.0003, -0.0053,  0.0233,  0.0112, -0.0014,  0.0028, -0.0282,  0.0211,\n",
            "        -0.0131,  0.0060, -0.0007,  0.0238, -0.0167,  0.0227,  0.0101,  0.0104,\n",
            "         0.0008, -0.0054,  0.0301,  0.0003, -0.0105, -0.0011, -0.0261,  0.0291,\n",
            "         0.0179, -0.0312,  0.0291,  0.0268,  0.0142, -0.0044, -0.0021,  0.0309,\n",
            "        -0.0217, -0.0062,  0.0061, -0.0287, -0.0063, -0.0005, -0.0103,  0.0279,\n",
            "        -0.0236,  0.0111, -0.0034,  0.0111,  0.0023, -0.0253,  0.0012,  0.0304,\n",
            "        -0.0032, -0.0162, -0.0098,  0.0136,  0.0227,  0.0141,  0.0159, -0.0311,\n",
            "        -0.0032, -0.0151, -0.0077, -0.0126,  0.0271,  0.0023, -0.0245, -0.0166,\n",
            "         0.0190,  0.0123, -0.0219,  0.0157, -0.0157, -0.0156, -0.0019,  0.0097,\n",
            "        -0.0298, -0.0154, -0.0145, -0.0083, -0.0160, -0.0095, -0.0116,  0.0160,\n",
            "        -0.0093, -0.0169,  0.0221, -0.0250, -0.0234,  0.0286, -0.0101, -0.0265],\n",
            "       device='cuda:0')\n",
            "decoder.gru.weight_ih_l0\n",
            "tensor([[ 0.0423,  0.0179, -0.0136,  ..., -0.0290,  0.0253, -0.0060],\n",
            "        [ 0.0168, -0.0098,  0.0070,  ..., -0.0323, -0.0072, -0.0265],\n",
            "        [ 0.0003, -0.0390, -0.0293,  ..., -0.0331,  0.0170, -0.0378],\n",
            "        ...,\n",
            "        [-0.0309,  0.0012, -0.0429,  ...,  0.0015, -0.0139, -0.0107],\n",
            "        [-0.0136,  0.0436, -0.0386,  ...,  0.0147, -0.0096,  0.0390],\n",
            "        [ 0.0248,  0.0217,  0.0063,  ...,  0.0033,  0.0290, -0.0346]],\n",
            "       device='cuda:0')\n",
            "decoder.gru.weight_hh_l0\n",
            "tensor([[-0.0178,  0.0218, -0.0212,  ...,  0.0030,  0.0105, -0.0332],\n",
            "        [-0.0054,  0.0208,  0.0285,  ...,  0.0006, -0.0246, -0.0099],\n",
            "        [ 0.0262,  0.0099,  0.0082,  ...,  0.0116,  0.0242, -0.0357],\n",
            "        ...,\n",
            "        [-0.0269, -0.0375, -0.0184,  ...,  0.0365,  0.0044, -0.0103],\n",
            "        [-0.0246,  0.0128, -0.0074,  ..., -0.0157, -0.0409, -0.0360],\n",
            "        [ 0.0049, -0.0353,  0.0307,  ..., -0.0121, -0.0164,  0.0278]],\n",
            "       device='cuda:0')\n",
            "decoder.gru.bias_ih_l0\n",
            "tensor([ 0.0239,  0.0276, -0.0214,  ...,  0.0331,  0.0208,  0.0301],\n",
            "       device='cuda:0')\n",
            "decoder.gru.bias_hh_l0\n",
            "tensor([-0.0424,  0.0104,  0.0222,  ...,  0.0058,  0.0086, -0.0059],\n",
            "       device='cuda:0')\n",
            "decoder.out.weight\n",
            "tensor([[ 0.0242,  0.0067,  0.0241,  ..., -0.0248, -0.0014,  0.0295],\n",
            "        [ 0.0010, -0.0190, -0.0273,  ...,  0.0053, -0.0151, -0.0145],\n",
            "        [-0.0166,  0.0072,  0.0029,  ..., -0.0253, -0.0032,  0.0257],\n",
            "        ...,\n",
            "        [-0.0104, -0.0086,  0.0154,  ..., -0.0041,  0.0008, -0.0192],\n",
            "        [-0.0082,  0.0243, -0.0226,  ...,  0.0205, -0.0164, -0.0245],\n",
            "        [ 0.0292, -0.0123,  0.0176,  ..., -0.0049, -0.0291,  0.0295]],\n",
            "       device='cuda:0')\n",
            "decoder.out.bias\n",
            "tensor([ 0.0197, -0.0275, -0.0286,  0.0109, -0.0014, -0.0170,  0.0163, -0.0037,\n",
            "         0.0087, -0.0178, -0.0107, -0.0020, -0.0298, -0.0256, -0.0221, -0.0073,\n",
            "         0.0073,  0.0131, -0.0133,  0.0218, -0.0201, -0.0159,  0.0044,  0.0074,\n",
            "        -0.0279,  0.0226,  0.0274, -0.0161,  0.0178, -0.0158,  0.0163,  0.0215,\n",
            "         0.0041,  0.0015,  0.0028,  0.0038, -0.0064,  0.0202,  0.0022,  0.0050,\n",
            "        -0.0240,  0.0135,  0.0311, -0.0059,  0.0216,  0.0214, -0.0098,  0.0077,\n",
            "         0.0192,  0.0204, -0.0084, -0.0151,  0.0106,  0.0257,  0.0262,  0.0110,\n",
            "        -0.0020,  0.0161, -0.0275, -0.0153, -0.0162, -0.0062,  0.0028,  0.0118,\n",
            "        -0.0312, -0.0209, -0.0192, -0.0185, -0.0048,  0.0168,  0.0088, -0.0265,\n",
            "        -0.0300,  0.0021, -0.0277, -0.0173, -0.0007, -0.0052, -0.0312,  0.0062,\n",
            "         0.0017, -0.0223, -0.0184,  0.0231, -0.0265, -0.0093,  0.0215, -0.0010,\n",
            "        -0.0297, -0.0259,  0.0198,  0.0187,  0.0118, -0.0242, -0.0199,  0.0221,\n",
            "         0.0002, -0.0249, -0.0094, -0.0163,  0.0266, -0.0257, -0.0299,  0.0289,\n",
            "         0.0060, -0.0259,  0.0045, -0.0173,  0.0186,  0.0103, -0.0067, -0.0207,\n",
            "         0.0063,  0.0244, -0.0080, -0.0167, -0.0285, -0.0041,  0.0073,  0.0207,\n",
            "         0.0282, -0.0141, -0.0068,  0.0196,  0.0275,  0.0291, -0.0263, -0.0047,\n",
            "         0.0082,  0.0217,  0.0186,  0.0127, -0.0268, -0.0206, -0.0052,  0.0146,\n",
            "        -0.0183, -0.0296,  0.0042,  0.0156,  0.0234,  0.0263,  0.0230,  0.0068,\n",
            "        -0.0158, -0.0204,  0.0294,  0.0057,  0.0056,  0.0039,  0.0297,  0.0130,\n",
            "        -0.0266,  0.0229, -0.0126, -0.0103, -0.0104,  0.0198, -0.0101,  0.0118,\n",
            "         0.0101, -0.0070,  0.0034,  0.0011,  0.0194,  0.0202, -0.0099, -0.0194,\n",
            "        -0.0074, -0.0271,  0.0287,  0.0137,  0.0183, -0.0050, -0.0301,  0.0147,\n",
            "         0.0196, -0.0252,  0.0072,  0.0308, -0.0090,  0.0252,  0.0025,  0.0226,\n",
            "        -0.0143, -0.0224, -0.0284,  0.0136,  0.0059, -0.0136,  0.0265, -0.0164,\n",
            "         0.0241,  0.0063,  0.0310, -0.0230, -0.0186,  0.0246, -0.0192, -0.0223,\n",
            "        -0.0038, -0.0127,  0.0124,  0.0272, -0.0016, -0.0246, -0.0110,  0.0110,\n",
            "        -0.0215, -0.0165,  0.0226, -0.0281,  0.0298, -0.0280,  0.0164, -0.0275,\n",
            "        -0.0027, -0.0251,  0.0081, -0.0088,  0.0100, -0.0191,  0.0251,  0.0034,\n",
            "        -0.0031, -0.0213, -0.0008, -0.0146, -0.0153, -0.0278, -0.0298,  0.0075,\n",
            "         0.0011, -0.0060,  0.0242,  0.0167,  0.0027, -0.0208,  0.0210,  0.0181,\n",
            "        -0.0207, -0.0049, -0.0002,  0.0072, -0.0119, -0.0044,  0.0033, -0.0245,\n",
            "        -0.0070,  0.0188, -0.0017, -0.0101, -0.0177,  0.0020, -0.0188,  0.0080,\n",
            "        -0.0059,  0.0300,  0.0277, -0.0057,  0.0054, -0.0279, -0.0269, -0.0193,\n",
            "         0.0093, -0.0279, -0.0246, -0.0304,  0.0023, -0.0203, -0.0194, -0.0250,\n",
            "        -0.0034, -0.0117, -0.0269,  0.0026, -0.0154, -0.0032, -0.0061, -0.0274,\n",
            "        -0.0311,  0.0093, -0.0073, -0.0228,  0.0312,  0.0174,  0.0082, -0.0099,\n",
            "        -0.0171, -0.0050, -0.0269,  0.0285, -0.0214,  0.0202, -0.0152,  0.0132,\n",
            "         0.0182,  0.0007, -0.0135,  0.0310,  0.0016, -0.0055,  0.0123,  0.0238,\n",
            "         0.0179,  0.0130,  0.0034, -0.0028, -0.0047, -0.0108,  0.0201,  0.0292,\n",
            "         0.0152,  0.0016, -0.0121, -0.0044, -0.0094,  0.0033,  0.0169,  0.0128,\n",
            "         0.0016, -0.0150,  0.0039, -0.0227,  0.0280, -0.0004, -0.0125,  0.0285,\n",
            "        -0.0312,  0.0026, -0.0225, -0.0249, -0.0215,  0.0192,  0.0171,  0.0128,\n",
            "         0.0257,  0.0002,  0.0048,  0.0282, -0.0113, -0.0247, -0.0150,  0.0213,\n",
            "        -0.0214,  0.0193,  0.0010, -0.0210,  0.0045, -0.0094, -0.0294,  0.0220,\n",
            "        -0.0204, -0.0263], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwko1RmQy_Gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = 'checkpoint_seq2seq_train_v0.pth'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuyNhVGyzGwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_loss = 'checkpoint_seq2seq_loss_v0.pth'\n",
        "path_loss = F\"/content/gdrive/My Drive/{model_save_loss}\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHTlAvJmyQG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sc4_VWGyvsn",
        "colab_type": "code",
        "outputId": "72bcbe3f-d106-4d24-9557-4f15d22ceb60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7185
        }
      },
      "source": [
        "for name,param in model.named_parameters():\n",
        "  print(name)\n",
        "  print(param.data)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder.embed.weight\n",
            "tensor([[ 0.3022, -0.1318,  1.9882,  ...,  0.2907, -0.3224,  0.5976],\n",
            "        [-0.7091, -0.9527,  0.1287,  ..., -0.3062,  0.0296,  0.3808],\n",
            "        [-0.8138, -0.8229, -0.3540,  ..., -0.5451, -1.4748, -1.4022],\n",
            "        ...,\n",
            "        [ 0.3804,  0.9543, -1.3726,  ..., -1.1366,  0.1893,  1.1785],\n",
            "        [-1.0030, -0.3153,  0.7899,  ...,  0.2195,  0.4086, -2.0941],\n",
            "        [-0.2088,  0.4728,  1.2621,  ..., -2.0619,  1.5998,  0.2934]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_ih_l0\n",
            "tensor([[ 0.1538, -0.1584,  0.0512,  ...,  0.1356,  0.0815, -0.1827],\n",
            "        [-0.1486,  0.3912,  0.1574,  ..., -0.0408, -0.0631, -0.2040],\n",
            "        [-0.0029,  0.0656,  0.3741,  ..., -0.1935,  0.2431, -0.2227],\n",
            "        ...,\n",
            "        [ 0.1009,  0.2239,  0.3391,  ...,  0.0924, -0.1031,  0.0724],\n",
            "        [ 0.2108,  0.0925,  0.0239,  ...,  0.1695, -0.2077, -0.2077],\n",
            "        [-0.0805,  0.2197, -0.2664,  ..., -0.2263, -0.0938, -0.1104]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_hh_l0\n",
            "tensor([[-0.0947, -0.1379, -0.0377,  ..., -0.1149,  0.0463,  0.1541],\n",
            "        [ 0.2901, -0.0027,  0.1886,  ...,  0.0222,  0.0630, -0.2728],\n",
            "        [-0.0163, -0.0795,  0.3024,  ..., -0.1644, -0.2093,  0.1574],\n",
            "        ...,\n",
            "        [-0.1635,  0.0666,  0.0096,  ...,  0.2286, -0.1456,  0.0382],\n",
            "        [ 0.0996,  0.2742,  0.1648,  ..., -0.0397,  0.3926, -0.2331],\n",
            "        [-0.0060,  0.3526,  0.0637,  ...,  0.1966,  0.3327, -0.1927]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_ih_l0\n",
            "tensor([-0.1995, -0.0033,  0.0328,  ..., -0.0918,  0.0760, -0.0659],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_hh_l0\n",
            "tensor([-0.1977, -0.0227, -0.0208,  ..., -0.1293,  0.1320,  0.0483],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_ih_l0_reverse\n",
            "tensor([[-0.0423, -0.0006, -0.0348,  ..., -0.0205, -0.0022, -0.0396],\n",
            "        [-0.0152,  0.0268,  0.0232,  ...,  0.0011, -0.0401, -0.0132],\n",
            "        [ 0.0340, -0.0126,  0.0036,  ...,  0.0071, -0.0043,  0.0176],\n",
            "        ...,\n",
            "        [ 0.0206,  0.0405,  0.0151,  ..., -0.0138, -0.0225,  0.0101],\n",
            "        [-0.0175,  0.0219, -0.0268,  ..., -0.0115, -0.0230, -0.0327],\n",
            "        [ 0.0307,  0.0387,  0.0228,  ...,  0.0125,  0.0349,  0.0049]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_hh_l0_reverse\n",
            "tensor([[-0.0277,  0.0354,  0.0275,  ...,  0.0008,  0.0136, -0.0368],\n",
            "        [ 0.0398, -0.0057,  0.0278,  ..., -0.0218, -0.0256, -0.0048],\n",
            "        [ 0.0202, -0.0408, -0.0094,  ..., -0.0082, -0.0287, -0.0250],\n",
            "        ...,\n",
            "        [ 0.0265,  0.0223,  0.0031,  ..., -0.0224, -0.0035,  0.0127],\n",
            "        [ 0.0118, -0.0423, -0.0190,  ..., -0.0380, -0.0064,  0.0221],\n",
            "        [ 0.0177, -0.0397, -0.0004,  ..., -0.0300, -0.0118, -0.0441]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_ih_l0_reverse\n",
            "tensor([ 0.0409,  0.0346, -0.0228,  ..., -0.0035,  0.0407,  0.0022],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_hh_l0_reverse\n",
            "tensor([ 0.0020, -0.0420, -0.0258,  ...,  0.0007, -0.0382, -0.0051],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_ih_l1\n",
            "tensor([[ 0.0360, -0.0326,  0.0355,  ...,  0.0276,  0.0387, -0.0217],\n",
            "        [-0.0357,  0.0148, -0.0022,  ..., -0.0030,  0.0260, -0.0290],\n",
            "        [ 0.0063, -0.0213,  0.0074,  ..., -0.0338, -0.0420, -0.0361],\n",
            "        ...,\n",
            "        [-0.0055, -0.0082, -0.0044,  ...,  0.0111,  0.0326, -0.0394],\n",
            "        [-0.0056, -0.0367,  0.0222,  ...,  0.0426,  0.0192,  0.0127],\n",
            "        [ 0.0434,  0.0092, -0.0294,  ...,  0.0408, -0.0255,  0.0220]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_hh_l1\n",
            "tensor([[-0.0086, -0.0187, -0.0382,  ..., -0.0079, -0.0436,  0.0176],\n",
            "        [-0.0437, -0.0297, -0.0251,  ...,  0.0280,  0.0205, -0.0171],\n",
            "        [-0.0354,  0.0229,  0.0427,  ...,  0.0416,  0.0390, -0.0118],\n",
            "        ...,\n",
            "        [-0.0240, -0.0089,  0.0414,  ...,  0.0180,  0.0147,  0.0411],\n",
            "        [-0.0195,  0.0018,  0.0052,  ..., -0.0228, -0.0160,  0.0357],\n",
            "        [ 0.0042, -0.0026,  0.0270,  ...,  0.0043, -0.0147, -0.0035]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_ih_l1\n",
            "tensor([ 0.0407, -0.0315, -0.0061,  ..., -0.0125,  0.0217,  0.0352],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_hh_l1\n",
            "tensor([ 0.0186,  0.0076, -0.0080,  ..., -0.0166, -0.0368, -0.0010],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_ih_l1_reverse\n",
            "tensor([[ 0.0213, -0.0386,  0.0288,  ...,  0.0187,  0.0334,  0.0211],\n",
            "        [-0.0184, -0.0394,  0.0292,  ...,  0.0038, -0.0319, -0.0095],\n",
            "        [ 0.0040,  0.0223,  0.0363,  ...,  0.0229, -0.0056, -0.0323],\n",
            "        ...,\n",
            "        [-0.0423,  0.0404,  0.0216,  ...,  0.0365, -0.0328, -0.0261],\n",
            "        [ 0.0192, -0.0375, -0.0339,  ...,  0.0115, -0.0058,  0.0345],\n",
            "        [ 0.0114, -0.0121, -0.0426,  ..., -0.0049,  0.0208, -0.0415]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.weight_hh_l1_reverse\n",
            "tensor([[ 0.0163,  0.0182, -0.0012,  ...,  0.0338, -0.0393,  0.0231],\n",
            "        [ 0.0417,  0.0120,  0.0328,  ...,  0.0253, -0.0157,  0.0143],\n",
            "        [ 0.0198,  0.0403, -0.0326,  ...,  0.0299,  0.0327, -0.0365],\n",
            "        ...,\n",
            "        [ 0.0049, -0.0301, -0.0269,  ..., -0.0017,  0.0274,  0.0402],\n",
            "        [ 0.0301,  0.0336,  0.0366,  ..., -0.0436,  0.0282,  0.0061],\n",
            "        [ 0.0253, -0.0273,  0.0039,  ...,  0.0025, -0.0307, -0.0010]],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_ih_l1_reverse\n",
            "tensor([-0.0384, -0.0217, -0.0116,  ..., -0.0319,  0.0283,  0.0269],\n",
            "       device='cuda:0')\n",
            "encoder.gru.bias_hh_l1_reverse\n",
            "tensor([ 0.0016,  0.0428,  0.0026,  ...,  0.0300, -0.0293,  0.0020],\n",
            "       device='cuda:0')\n",
            "decoder.embed.weight\n",
            "tensor([[ 1.3847, -1.4302, -1.4297,  ..., -0.4880,  1.1395, -0.1472],\n",
            "        [-0.3003, -0.1318,  0.1476,  ..., -0.2176,  0.1241,  0.1942],\n",
            "        [-0.0832,  0.0385, -0.1738,  ..., -0.1401, -0.2079, -0.2592],\n",
            "        ...,\n",
            "        [-1.7104,  1.1865,  0.1542,  ...,  1.1898,  0.4978,  0.3871],\n",
            "        [-0.4039, -0.2543, -0.1636,  ...,  0.8824, -0.1311, -0.8869],\n",
            "        [ 0.7496, -1.6724, -0.6839,  ..., -0.6736, -0.1973,  0.3819]],\n",
            "       device='cuda:0')\n",
            "decoder.attention.v\n",
            "tensor([ 2.8527e-02, -3.1956e-02,  1.7444e-03, -2.7574e-02, -7.3549e-03,\n",
            "        -6.2839e-03, -4.1775e-02,  3.8567e-03, -4.4042e-02,  3.2123e-02,\n",
            "        -2.8815e-02, -1.9988e-02, -2.7728e-02,  3.1080e-03, -4.2928e-02,\n",
            "        -3.6658e-02, -3.0097e-02, -2.1462e-02, -1.9247e-02, -3.2010e-02,\n",
            "        -4.4989e-03, -4.6036e-02,  3.6119e-02,  3.5245e-02, -2.9500e-02,\n",
            "        -1.4318e-02, -2.4195e-03, -4.0236e-02, -4.0486e-02, -2.1262e-02,\n",
            "        -9.4630e-04,  2.9207e-02,  9.9190e-03, -2.9022e-02, -4.5108e-02,\n",
            "         2.9907e-02,  2.9008e-02,  3.0548e-02, -4.5987e-02, -4.6430e-02,\n",
            "        -2.6177e-02,  1.1307e-02,  9.8319e-05, -1.6269e-02, -1.3617e-02,\n",
            "        -1.0916e-02, -1.1565e-02, -4.6187e-02, -1.2562e-02, -2.4245e-02,\n",
            "         2.2367e-02,  2.0044e-02, -2.4397e-02,  3.7724e-03, -2.2960e-02,\n",
            "        -1.2640e-02,  1.5065e-02, -1.9436e-02, -4.4600e-02, -2.0835e-02,\n",
            "         3.4188e-02,  2.4684e-02,  7.8077e-03, -2.1641e-02, -3.2518e-02,\n",
            "         7.3818e-03,  8.7637e-03, -4.0761e-02,  1.9030e-02,  1.4500e-02,\n",
            "        -6.2661e-03,  1.0840e-02, -1.7389e-02, -2.0720e-02,  3.9733e-02,\n",
            "        -1.2340e-02,  3.6092e-02,  9.1979e-03,  3.7555e-02,  3.1611e-02,\n",
            "        -2.7065e-03,  1.3032e-03,  2.8939e-02, -4.5567e-02, -1.5062e-02,\n",
            "        -1.5251e-03, -1.8041e-02, -4.0922e-02,  2.3319e-02,  2.1981e-02,\n",
            "        -2.2421e-02, -2.2975e-02, -2.7864e-03,  2.2457e-02,  3.7978e-02,\n",
            "         8.7163e-03, -2.0360e-02,  2.5638e-02,  1.2258e-02,  3.5351e-02,\n",
            "        -7.8557e-03,  1.0687e-02, -4.7574e-02, -2.6301e-02, -4.3973e-02,\n",
            "         2.4350e-02, -2.9432e-02, -2.0580e-02,  4.6414e-03, -2.3971e-02,\n",
            "         1.7250e-02, -1.4915e-02,  3.3198e-02, -2.3016e-02, -1.6287e-02,\n",
            "         1.8002e-02,  2.4993e-02, -3.3988e-03,  3.4528e-03, -2.1898e-03,\n",
            "         5.9677e-03,  3.9468e-02,  1.5441e-02,  1.3005e-02, -2.5489e-02,\n",
            "        -2.1916e-02, -1.6289e-02, -3.9992e-02,  2.1630e-02, -1.7830e-02,\n",
            "        -7.1586e-04, -7.3241e-04,  2.6994e-02, -2.3433e-02,  4.4165e-04,\n",
            "        -4.1939e-02,  1.2192e-02, -4.5841e-02, -2.5426e-02,  2.1568e-02,\n",
            "         1.5651e-02, -3.0647e-02, -2.8931e-02, -2.3900e-02, -2.0063e-02,\n",
            "        -3.7096e-02, -1.5239e-02,  2.5863e-02,  2.4538e-02, -2.5661e-02,\n",
            "         3.0665e-02,  3.8429e-02,  2.7034e-02, -3.8478e-02, -3.7589e-02,\n",
            "         1.8521e-02, -4.8949e-03,  1.7674e-02, -2.3145e-02, -7.1749e-03,\n",
            "         7.5412e-03, -3.9553e-02, -2.4423e-02, -1.7505e-02, -2.1219e-02,\n",
            "        -3.5865e-03,  2.1363e-02, -3.4895e-02,  8.7040e-03,  2.8627e-02,\n",
            "         2.7061e-03,  1.9528e-02,  1.5065e-02, -4.0147e-02, -3.0163e-02,\n",
            "         1.7086e-02, -1.4017e-02, -5.7491e-03, -7.9462e-03,  3.7942e-02,\n",
            "        -1.6832e-02,  3.7860e-02, -9.3373e-03,  1.2734e-02, -1.5162e-02,\n",
            "        -3.0048e-02, -7.0486e-03, -3.2779e-02, -7.0107e-03, -3.3354e-02,\n",
            "         2.0199e-02,  1.1024e-02, -4.7126e-02,  1.4560e-02,  3.5873e-02,\n",
            "         5.4460e-03,  2.1545e-02, -6.8513e-03,  1.0269e-02, -1.6766e-02,\n",
            "        -3.0077e-02,  3.3663e-02,  1.8536e-02, -3.3388e-02, -2.3026e-02,\n",
            "        -7.5672e-03,  1.2568e-02, -3.4067e-02, -4.6153e-02, -9.7161e-03,\n",
            "         2.7487e-02,  7.4309e-04,  2.5614e-02, -2.8982e-02, -3.9111e-02,\n",
            "         7.0246e-03, -6.8064e-03,  4.2679e-03,  2.2637e-03, -3.8613e-02,\n",
            "         3.9292e-02, -1.3875e-02,  4.0058e-02, -1.8975e-02, -4.0721e-02,\n",
            "        -1.6478e-03,  3.2716e-02,  1.2087e-02, -4.1171e-03, -1.5276e-02,\n",
            "        -3.5354e-02, -2.9611e-02,  3.8767e-02,  2.1075e-03,  1.0713e-02,\n",
            "         7.3892e-03, -1.6687e-02,  2.0702e-02,  2.8455e-02,  3.5291e-02,\n",
            "         9.2643e-03,  3.2082e-02, -4.5449e-02,  3.4051e-02,  1.7442e-02,\n",
            "         1.6789e-03,  2.5450e-03, -2.8780e-04,  5.3071e-03, -2.7574e-02,\n",
            "        -3.1320e-03, -1.5756e-02, -4.0852e-03, -1.1314e-02, -3.7042e-02,\n",
            "         8.6834e-03,  2.1498e-02, -2.3067e-02,  3.9206e-02, -4.2576e-02,\n",
            "         1.4300e-02,  4.6412e-03,  2.5304e-02, -3.0154e-02,  2.4741e-02,\n",
            "         1.3540e-02, -6.9954e-03,  4.1681e-03, -4.8227e-02,  1.3041e-02,\n",
            "         3.7106e-02, -2.7630e-02,  3.1678e-02, -2.5187e-02,  6.7411e-03,\n",
            "        -2.3352e-02, -1.4517e-02,  3.6787e-02, -4.4043e-02, -4.1603e-02,\n",
            "         4.0158e-02,  1.4265e-02, -2.3204e-02,  9.9375e-03, -3.6549e-02,\n",
            "        -1.9064e-03, -8.1975e-03, -9.7616e-04, -3.1673e-04,  3.1672e-02,\n",
            "         7.3922e-03, -2.7322e-02,  1.1089e-03,  2.2949e-02, -3.5953e-02,\n",
            "         3.1099e-02, -4.2995e-02, -2.0722e-03,  4.2269e-03, -4.0749e-02,\n",
            "        -2.7306e-02, -1.3146e-02, -3.8748e-02,  3.4186e-02,  2.0747e-02,\n",
            "         2.0536e-02, -2.7513e-02,  2.4900e-02,  1.7823e-02, -8.6355e-04,\n",
            "        -1.7332e-02,  6.9144e-03, -4.1274e-04,  3.5826e-02, -1.2308e-02,\n",
            "         2.8267e-02,  3.6073e-02,  3.0001e-02,  1.2976e-02, -4.3329e-02,\n",
            "        -1.1574e-02,  3.6783e-02, -1.7847e-03,  1.7904e-02, -8.7535e-03,\n",
            "        -5.8000e-04,  3.1530e-02,  1.4131e-02, -2.5503e-02,  3.3944e-03,\n",
            "        -1.0279e-02, -2.1213e-02, -4.0164e-02,  7.2532e-03,  7.0773e-03,\n",
            "        -4.1867e-02, -3.3975e-02,  2.7206e-02,  1.2928e-02, -2.2453e-02,\n",
            "        -1.4019e-02, -1.1000e-02,  7.0213e-03, -3.0958e-02,  2.7295e-02,\n",
            "        -2.3562e-02,  6.4213e-03, -4.1454e-02, -2.8794e-03, -2.1157e-03,\n",
            "         3.1370e-02, -2.1041e-02, -4.6319e-02,  7.9910e-03,  1.8188e-02,\n",
            "        -3.1127e-02,  8.1488e-03, -2.5641e-02, -1.5318e-03, -4.2102e-03,\n",
            "         2.6541e-02, -3.0432e-02,  2.4576e-02,  3.7246e-02, -7.0157e-04,\n",
            "        -3.0120e-03, -2.8154e-02,  6.7299e-04, -3.7593e-02,  3.5537e-02,\n",
            "         2.8114e-02, -4.2532e-02, -3.1153e-02,  3.1469e-02, -4.0198e-02,\n",
            "        -3.2592e-02,  2.8825e-02, -6.3463e-03, -3.7138e-02,  1.7163e-02,\n",
            "         2.7536e-02,  3.3307e-02,  3.0028e-02,  3.7820e-03, -3.1760e-02,\n",
            "         4.5442e-03, -1.6685e-02, -1.5530e-02, -4.0000e-02, -4.0783e-02,\n",
            "        -1.0169e-02,  2.1341e-02, -8.4377e-03, -3.8192e-02,  3.5383e-02,\n",
            "         2.5380e-02,  6.3540e-03, -2.7076e-02,  3.6928e-02, -1.6280e-02,\n",
            "        -1.4469e-02, -3.4957e-02,  1.2036e-02,  2.6467e-02,  6.6741e-03,\n",
            "        -2.5162e-02, -2.1156e-02,  8.4682e-03,  2.2920e-03,  4.0414e-02,\n",
            "        -9.6229e-03,  2.5425e-02,  1.9844e-02,  4.3285e-03, -5.1919e-03,\n",
            "         3.9340e-02,  3.4032e-02, -4.3777e-02,  2.9906e-02,  3.4052e-02,\n",
            "         2.9638e-02, -1.9985e-02,  3.1176e-02, -4.2753e-02, -1.7818e-02,\n",
            "         2.2733e-02, -1.7935e-02, -7.7071e-03,  1.3374e-02, -1.0948e-02,\n",
            "        -4.5023e-03, -2.0455e-02,  3.4010e-02,  2.3373e-02, -1.3410e-02,\n",
            "        -1.1072e-02,  5.0162e-03,  3.3804e-03, -2.5462e-02, -2.1068e-02,\n",
            "        -1.9779e-02, -1.8555e-02, -2.8424e-02, -4.1596e-02,  1.2109e-02,\n",
            "         3.6116e-02,  7.5269e-03,  2.6286e-02, -8.3830e-03, -1.2829e-02,\n",
            "        -8.7106e-03, -1.7952e-03,  2.1981e-02, -3.9244e-02, -3.1004e-02,\n",
            "         9.3067e-03, -8.2014e-03, -4.8319e-03, -1.9056e-02, -3.1465e-02,\n",
            "        -1.6358e-02, -2.2623e-02, -1.5675e-02,  5.7172e-04, -4.1423e-02,\n",
            "         3.7119e-03, -4.0342e-02, -3.5891e-02, -1.7866e-02,  2.8720e-02,\n",
            "        -3.4893e-02, -4.5659e-02,  1.2720e-02, -2.3422e-02,  2.1952e-02,\n",
            "         2.8109e-02, -3.8660e-02, -1.2669e-02,  6.8372e-03,  4.3803e-03,\n",
            "         3.1307e-03, -3.3806e-02,  7.9599e-03,  1.0964e-02, -4.3692e-02,\n",
            "        -4.2494e-02, -4.8837e-03, -1.6233e-02, -3.1701e-02,  6.7082e-03,\n",
            "         9.3806e-03,  3.0947e-02, -3.9105e-02, -2.8498e-02, -3.6468e-02,\n",
            "         3.3780e-02,  7.3131e-03, -2.4466e-02, -2.7364e-02, -1.2262e-03,\n",
            "        -7.1613e-03, -1.2719e-02, -2.0731e-02, -6.9604e-03, -4.3997e-02,\n",
            "         7.8778e-04, -1.4051e-02, -4.5366e-02,  1.4115e-02, -2.1904e-02,\n",
            "        -1.3446e-02, -1.4328e-02], device='cuda:0')\n",
            "decoder.attention.attn.weight\n",
            "tensor([[ 0.0250,  0.0235,  0.0218,  ...,  0.0170,  0.0023,  0.0118],\n",
            "        [ 0.0237, -0.0157,  0.0302,  ...,  0.0089, -0.0020, -0.0159],\n",
            "        [-0.0061, -0.0064, -0.0270,  ...,  0.0082, -0.0289, -0.0209],\n",
            "        ...,\n",
            "        [-0.0026, -0.0080,  0.0085,  ...,  0.0009,  0.0264,  0.0173],\n",
            "        [-0.0023,  0.0279, -0.0216,  ...,  0.0216, -0.0165,  0.0049],\n",
            "        [-0.0085, -0.0216,  0.0118,  ..., -0.0291,  0.0095,  0.0001]],\n",
            "       device='cuda:0')\n",
            "decoder.attention.attn.bias\n",
            "tensor([-1.3272e-02, -2.4616e-02, -3.6898e-03, -4.6178e-03, -2.8541e-02,\n",
            "         3.1087e-02, -1.8360e-02, -2.9716e-02, -5.4267e-03, -1.4351e-02,\n",
            "         1.1496e-02, -4.8454e-03,  3.1224e-02, -4.3424e-03,  3.1145e-02,\n",
            "        -8.4717e-03, -8.8607e-03,  1.8164e-02,  7.0176e-03, -1.4386e-02,\n",
            "        -3.0732e-02, -1.4155e-02,  5.1578e-03, -9.1427e-03, -8.1546e-03,\n",
            "         2.8732e-02,  2.9561e-03, -5.9509e-03,  9.9984e-03, -3.0175e-02,\n",
            "         2.6686e-02,  3.0085e-02, -2.5023e-02, -1.4835e-02,  8.7751e-03,\n",
            "        -1.3550e-02, -2.0028e-03,  1.8289e-02,  7.0890e-03, -6.9475e-03,\n",
            "        -6.5667e-03, -6.6536e-03,  2.0887e-02,  1.9710e-02, -1.1849e-02,\n",
            "         3.1047e-03, -1.1495e-02, -1.0037e-02, -7.8766e-03,  7.5191e-03,\n",
            "        -7.0815e-03, -1.8492e-02,  2.6109e-03,  1.5470e-03, -2.3511e-03,\n",
            "        -7.6861e-04,  1.9030e-03,  2.7047e-02, -1.1080e-02,  3.0450e-02,\n",
            "         2.4963e-02,  2.3221e-02,  2.7139e-02, -2.4929e-02, -2.1348e-02,\n",
            "        -2.9639e-03,  9.1127e-03, -2.1680e-02, -1.7299e-02,  1.0202e-02,\n",
            "        -1.9318e-03, -1.2069e-02,  1.4890e-02,  2.2504e-02, -2.7230e-02,\n",
            "         2.8265e-02, -1.7608e-02, -1.5944e-02, -2.6145e-02, -8.6444e-03,\n",
            "        -2.7726e-02, -1.4382e-02, -2.2838e-02, -2.5421e-02, -2.2877e-02,\n",
            "        -2.1094e-02,  2.2218e-02,  2.3269e-02, -3.0443e-02,  8.2331e-03,\n",
            "        -1.2196e-02,  2.5978e-02, -2.7849e-02, -1.9309e-02, -1.0060e-03,\n",
            "         5.0249e-03, -2.4727e-02, -8.2844e-03, -2.4972e-03, -9.8737e-03,\n",
            "         1.1382e-02,  7.2970e-03,  2.8754e-02,  1.1806e-02,  2.8486e-02,\n",
            "        -1.1471e-02,  1.8170e-02,  3.0931e-02,  2.9584e-02,  2.4854e-02,\n",
            "         2.9398e-02, -8.4686e-03, -4.2205e-03,  1.6011e-02,  2.3810e-02,\n",
            "        -1.0551e-03,  1.0091e-02, -1.4416e-03,  2.4811e-02, -4.4228e-03,\n",
            "         7.4382e-03, -1.2788e-02,  2.7968e-02, -1.3888e-02,  1.2019e-02,\n",
            "         8.9905e-03,  2.6969e-02,  1.0425e-02, -2.8091e-02, -1.0058e-02,\n",
            "        -1.9789e-02, -9.3229e-03, -1.5196e-02,  2.7258e-03,  1.0232e-03,\n",
            "        -2.7324e-02, -6.1750e-03,  2.3230e-02, -5.0360e-03, -2.5328e-02,\n",
            "         2.4491e-02,  9.2023e-04,  3.9244e-03,  5.8340e-05, -2.1402e-02,\n",
            "        -1.0022e-02,  3.9282e-03,  1.9822e-02, -2.0384e-04,  2.3429e-02,\n",
            "         4.9392e-03, -2.6221e-02,  2.5383e-02,  9.1052e-03, -2.1254e-02,\n",
            "        -2.7356e-02,  7.7846e-03, -2.5939e-02, -2.4811e-02,  9.6467e-03,\n",
            "        -3.1006e-02,  1.8165e-03,  8.5741e-03,  1.6462e-02,  1.5048e-02,\n",
            "         1.8837e-02,  2.8726e-02,  1.9882e-02, -7.1808e-03, -3.8057e-03,\n",
            "         8.3668e-03, -1.6456e-03, -1.9341e-02, -5.9901e-03,  1.5493e-02,\n",
            "        -9.3290e-03, -3.2427e-03,  2.5184e-03,  9.0303e-03,  3.3141e-03,\n",
            "        -1.3214e-02,  1.4311e-02, -2.4946e-03,  1.2926e-02, -1.7620e-02,\n",
            "         7.7702e-03, -2.2868e-02,  1.4837e-02,  1.7429e-02, -2.5894e-02,\n",
            "         2.6223e-02,  2.5189e-02,  3.0958e-02, -1.5853e-02, -2.5460e-02,\n",
            "         2.3807e-02, -1.5912e-02,  2.1508e-02, -2.6655e-02, -1.2415e-02,\n",
            "        -1.0227e-02, -2.8286e-02, -2.6136e-02, -1.5726e-02,  1.7135e-02,\n",
            "        -2.3640e-03, -2.8970e-02,  1.2118e-02,  1.0968e-02, -2.3393e-02,\n",
            "        -2.0851e-02,  3.3658e-03,  1.2627e-02,  2.8874e-02,  4.4106e-03,\n",
            "         1.4702e-02, -1.5839e-02,  1.3293e-02,  2.4008e-02, -1.4907e-02,\n",
            "         2.8220e-02,  9.2832e-03,  7.4316e-03, -1.5575e-02,  3.1621e-02,\n",
            "         5.6205e-04, -9.5602e-03,  2.8202e-02, -5.6214e-03, -2.5486e-02,\n",
            "        -1.8236e-02, -2.3019e-02,  5.9214e-03,  1.5511e-02, -2.0351e-02,\n",
            "         1.9377e-02, -1.5355e-02,  1.5619e-02, -5.0266e-05,  7.4807e-03,\n",
            "        -2.3564e-02, -4.4353e-03,  9.6545e-03,  1.4289e-02, -2.0527e-03,\n",
            "         8.8853e-03, -5.2390e-03,  2.5426e-02,  1.2308e-02,  4.7577e-03,\n",
            "         7.9585e-03, -3.0106e-02, -2.0885e-02,  6.1170e-03,  8.0285e-03,\n",
            "         2.9590e-02, -2.2187e-02,  3.0813e-02, -3.2061e-04, -7.2794e-03,\n",
            "        -6.1716e-03,  2.9455e-02,  2.2370e-02, -1.7095e-02, -1.3831e-02,\n",
            "        -1.1458e-02, -2.8691e-02,  1.6167e-02, -1.2467e-03,  2.2879e-02,\n",
            "         8.9379e-03,  4.1314e-03, -2.2442e-02, -1.8709e-02,  2.1588e-02,\n",
            "        -2.0462e-02,  1.9370e-02,  6.3739e-03, -5.1072e-03, -1.7908e-02,\n",
            "        -2.2099e-02, -2.3143e-02, -2.9099e-02,  6.5586e-03, -2.9544e-02,\n",
            "        -6.8233e-05,  3.4618e-03, -1.7306e-02,  1.3301e-02,  6.5871e-03,\n",
            "        -1.4128e-03,  1.6089e-02, -2.6539e-02,  7.0399e-03, -2.6930e-02,\n",
            "        -7.3052e-03, -2.7414e-02,  2.3092e-02,  6.6988e-03, -2.5130e-02,\n",
            "         3.8247e-03,  6.2881e-03, -3.1656e-03, -6.4676e-03,  4.8990e-03,\n",
            "         4.5246e-04, -1.9339e-02,  1.7752e-02,  1.6509e-02, -9.9792e-03,\n",
            "        -4.5815e-03,  2.1632e-02, -7.0158e-03,  8.4798e-03, -2.7983e-02,\n",
            "         2.9240e-02, -1.9955e-03, -2.5707e-02, -1.4005e-02, -1.6456e-02,\n",
            "         2.6198e-02,  1.9606e-02,  9.6562e-03, -2.8977e-02,  2.6149e-03,\n",
            "         3.0282e-02, -1.3995e-02, -7.3533e-03, -1.0746e-02,  1.4869e-02,\n",
            "        -4.5311e-03,  1.4217e-02,  2.7695e-02,  1.5632e-02, -1.8976e-02,\n",
            "         2.5688e-02, -1.8708e-02, -3.0078e-02, -2.0612e-02,  8.0527e-04,\n",
            "        -2.5385e-02, -1.3849e-02,  2.8217e-02, -2.8089e-02,  5.9510e-03,\n",
            "         2.6842e-02,  4.8275e-03,  2.9474e-02,  7.7232e-03,  2.1878e-02,\n",
            "        -8.7838e-03,  2.1268e-02,  1.4476e-02, -2.0597e-02,  2.6921e-03,\n",
            "        -3.0828e-02, -2.1019e-02, -1.9930e-02,  3.5759e-03,  1.3637e-02,\n",
            "         1.3758e-02, -2.8251e-02, -2.6839e-03, -1.7135e-02,  2.7041e-02,\n",
            "        -1.2675e-02,  2.3911e-02, -1.5201e-02,  2.4649e-02, -1.7648e-02,\n",
            "         3.0101e-02, -4.8340e-03,  1.2453e-02,  8.7246e-03,  7.6687e-03,\n",
            "         1.0716e-02, -3.0143e-02, -2.5190e-02,  2.7773e-02,  2.5095e-02,\n",
            "         2.6533e-03,  3.1353e-03,  6.1496e-03, -2.1183e-02,  1.0225e-02,\n",
            "         1.4647e-02, -2.5619e-02,  8.7564e-03,  1.1609e-02,  2.0237e-02,\n",
            "        -1.0765e-02,  2.2897e-02, -2.6742e-02, -2.1937e-02,  1.5792e-02,\n",
            "         1.8029e-03, -1.6526e-02,  3.0818e-03,  1.9647e-02, -1.3102e-02,\n",
            "        -1.6640e-02, -3.0379e-03, -1.7018e-02, -3.5871e-03, -1.5711e-02,\n",
            "        -1.9800e-03,  2.3308e-02,  2.1945e-02, -8.6796e-03,  4.8204e-03,\n",
            "         2.6135e-02,  2.5637e-02,  1.7088e-02,  2.9435e-02, -2.9676e-02,\n",
            "        -1.5023e-02,  2.8406e-02,  1.2190e-02, -2.0629e-02,  6.6394e-03,\n",
            "         1.7908e-02, -3.0158e-03, -1.2008e-02, -2.6331e-02,  3.7003e-03,\n",
            "         6.1384e-03,  2.8210e-02,  8.0495e-03,  2.2267e-02,  2.2268e-02,\n",
            "         2.5014e-02,  1.5492e-02,  1.7251e-02, -2.4310e-02, -2.5704e-02,\n",
            "         5.7503e-03,  1.9078e-02, -1.9128e-02,  2.0867e-02,  1.3783e-02,\n",
            "         2.4774e-02, -1.1322e-02, -1.9447e-02,  3.0698e-02, -3.0968e-02,\n",
            "        -2.2282e-02,  1.2094e-02,  2.8308e-02, -2.7130e-02, -2.9032e-02,\n",
            "         2.1229e-03, -1.4801e-02,  1.0576e-02, -1.0634e-02,  2.5955e-02,\n",
            "        -8.8811e-03, -2.5836e-03, -8.5251e-03,  2.5727e-02,  4.4558e-03,\n",
            "        -2.3210e-03,  8.1989e-03, -7.0288e-04,  2.6014e-03, -3.0020e-02,\n",
            "         7.2895e-03,  1.0960e-03,  2.3630e-03, -1.2146e-02,  1.3498e-02,\n",
            "         1.7342e-02,  2.1759e-03, -1.4300e-02, -6.5485e-03, -1.4430e-02,\n",
            "        -1.4963e-02, -2.0664e-02,  1.5441e-02,  1.6353e-02,  1.1539e-02,\n",
            "         3.9587e-04,  2.6700e-02,  1.0824e-02,  1.9586e-02,  2.4796e-02,\n",
            "         2.0469e-02, -2.7516e-02,  2.9437e-02,  1.7029e-02,  2.8506e-02,\n",
            "        -2.4535e-02,  7.7546e-03, -1.2358e-02, -2.5954e-02,  1.1669e-03,\n",
            "         2.4348e-02, -1.6352e-02, -1.4306e-02, -2.9187e-02,  1.2175e-02,\n",
            "         9.7273e-03, -1.0823e-02,  5.6404e-03, -2.9600e-02,  1.3910e-02,\n",
            "        -2.3586e-02,  3.8376e-03,  2.8304e-02,  2.7008e-02,  1.7687e-02,\n",
            "         1.5175e-02,  7.9229e-03], device='cuda:0')\n",
            "decoder.gru.weight_ih_l0\n",
            "tensor([[ 4.9740e-02,  3.4654e-01,  1.9299e-01,  ..., -2.4487e-02,\n",
            "          2.7085e-02,  2.1263e-02],\n",
            "        [-2.9053e-01,  2.3217e-01,  1.8973e-01,  ..., -2.7926e-02,\n",
            "          3.6282e-03,  5.3683e-04],\n",
            "        [ 1.3317e-01,  2.4754e-01,  3.2648e-01,  ..., -6.5241e-03,\n",
            "          1.8166e-04, -3.7918e-02],\n",
            "        ...,\n",
            "        [ 1.3036e-01,  2.4868e-01, -2.3011e-01,  ...,  6.0289e-03,\n",
            "         -2.9217e-02, -4.1031e-02],\n",
            "        [-1.8548e-02, -5.4289e-02,  1.2345e-03,  ..., -4.8783e-03,\n",
            "          7.6625e-04,  3.8066e-02],\n",
            "        [ 1.9298e-01, -1.0426e-01, -3.4479e-01,  ...,  3.0819e-02,\n",
            "         -7.8922e-03, -3.2837e-03]], device='cuda:0')\n",
            "decoder.gru.weight_hh_l0\n",
            "tensor([[ 0.1502, -0.2250, -0.0992,  ..., -0.0651,  0.1541,  0.1031],\n",
            "        [ 0.1513, -0.0559,  0.0113,  ..., -0.1698,  0.2520, -0.0654],\n",
            "        [ 0.1839,  0.3190,  0.1909,  ..., -0.0476,  0.1024, -0.0245],\n",
            "        ...,\n",
            "        [-0.2915,  0.0694,  0.0988,  ..., -0.1861,  0.3419, -0.0628],\n",
            "        [-0.0342,  0.1915, -0.0571,  ...,  0.0613,  0.1219,  0.1484],\n",
            "        [-0.0636, -0.2487,  0.0385,  ..., -0.0636,  0.2921, -0.1152]],\n",
            "       device='cuda:0')\n",
            "decoder.gru.bias_ih_l0\n",
            "tensor([ 0.1549,  0.0658,  0.2280,  ...,  0.5636, -0.2159,  0.8470],\n",
            "       device='cuda:0')\n",
            "decoder.gru.bias_hh_l0\n",
            "tensor([ 0.1637,  0.0290,  0.3145,  ...,  0.3524, -0.1905,  0.3979],\n",
            "       device='cuda:0')\n",
            "decoder.out.weight\n",
            "tensor([[-0.0167,  0.0372, -0.0087,  ..., -0.0072,  0.0042,  0.0019],\n",
            "        [ 0.0453,  0.0466,  0.0027,  ...,  0.0003,  0.0231, -0.0205],\n",
            "        [-0.0130,  0.0463, -0.0376,  ..., -0.0260,  0.0077,  0.0132],\n",
            "        ...,\n",
            "        [ 0.1040,  0.2740, -0.1084,  ..., -0.0222, -0.0228,  0.0105],\n",
            "        [-0.1762,  0.0302,  0.0225,  ...,  0.0292, -0.0009, -0.0073],\n",
            "        [-0.0102,  0.0734, -0.0354,  ...,  0.0053,  0.0165,  0.0212]],\n",
            "       device='cuda:0')\n",
            "decoder.out.bias\n",
            "tensor([-0.0863,  0.4166, -0.0920,  0.4166,  0.2626,  0.3071,  0.1382,  0.1104,\n",
            "         0.2255,  0.1594, -0.0269,  0.1161,  0.1601,  0.2962, -0.0482,  0.0530,\n",
            "         0.0232,  0.0775,  0.0245,  0.0230, -0.1102, -0.0686,  0.0084,  0.0249,\n",
            "         0.3155, -0.0134,  0.0648,  0.0436,  0.0787, -0.0245, -0.0059, -0.0132,\n",
            "        -0.0279, -0.0876, -0.0256,  0.0902,  0.0330, -0.0110,  0.0992,  0.1393,\n",
            "        -0.0108, -0.1153, -0.0667, -0.0078, -0.0462, -0.0778, -0.0290,  0.0005,\n",
            "        -0.1066, -0.0576, -0.1370, -0.1566,  0.0090, -0.0976, -0.0464, -0.0530,\n",
            "        -0.0631,  0.0038, -0.1213, -0.0924, -0.0617, -0.1548, -0.1322,  0.0408,\n",
            "         0.0163, -0.1778, -0.0347, -0.0499, -0.1258, -0.0986, -0.0144, -0.0809,\n",
            "        -0.1586, -0.0581, -0.0770, -0.1143, -0.0941,  0.0466, -0.0846, -0.1075,\n",
            "         0.0207, -0.1310,  0.0647, -0.2234, -0.2023, -0.3175, -0.2548, -0.1655,\n",
            "        -0.2194, -0.1427, -0.1058, -0.1400,  0.0544, -0.1241, -0.0805, -0.0472,\n",
            "        -0.1969,  0.0560,  0.1039, -0.0416, -0.0884,  0.0305, -0.0294, -0.0437,\n",
            "        -0.0344, -0.1142, -0.0953, -0.0814, -0.0686,  0.1155, -0.1283, -0.0191,\n",
            "         0.0134, -0.1043, -0.0944, -0.1140, -0.0591, -0.1031, -0.0949, -0.0602,\n",
            "         0.0199, -0.0193, -0.0857, -0.1905, -0.0394, -0.1408, -0.1140, -0.1796,\n",
            "        -0.2360, -0.0867, -0.0082, -0.0587,  0.0173, -0.1678, -0.0624, -0.0973,\n",
            "        -0.0981, -0.0379, -0.0279, -0.0713, -0.1227, -0.1000, -0.0753, -0.0140,\n",
            "        -0.1158, -0.1322, -0.0675, -0.1856,  0.0720, -0.1586, -0.1834, -0.0888,\n",
            "        -0.0873, -0.1143, -0.0729, -0.0294, -0.0318, -0.1340, -0.2604, -0.1324,\n",
            "        -0.0618, -0.0931, -0.3442, -0.1021, -0.0978, -0.0061, -0.0462, -0.0412,\n",
            "        -0.1070, -0.0152, -0.0307, -0.0171, -0.0614, -0.0479, -0.0350, -0.1336,\n",
            "        -0.1772, -0.0303, -0.0438, -0.0351, -0.0280, -0.0604, -0.0099, -0.1254,\n",
            "         0.0123, -0.0786, -0.1136, -0.1305, -0.0548, -0.0076, -0.0606, -0.0521,\n",
            "        -0.0220, -0.0438, -0.0645, -0.1137,  0.0520, -0.1106, -0.1037, -0.1297,\n",
            "        -0.0801, -0.1050, -0.0188, -0.0876, -0.0885, -0.2947, -0.2778, -0.2519,\n",
            "        -0.2303, -0.0606, -0.0629, -0.0822, -0.0627,  0.0010, -0.3244, -0.0184,\n",
            "        -0.1460, -0.0813, -0.1110, -0.1601, -0.1276, -0.1416, -0.0497, -0.0792,\n",
            "        -0.1875, -0.0667, -0.1667, -0.1070, -0.0152, -0.1274, -0.0764, -0.0217,\n",
            "        -0.0622, -0.0500, -0.0195, -0.0551, -0.1252, -0.1106, -0.2585, -0.1222,\n",
            "        -0.0632, -0.1915, -0.2529, -0.1435, -0.0365, -0.0719, -0.1495, -0.1466,\n",
            "        -0.0290, -0.1174, -0.1117, -0.0156, -0.0454, -0.1070, -0.0211, -0.0558,\n",
            "        -0.0186, -0.1837, -0.0602, -0.2639, -0.0598, -0.1285, -0.0010, -0.1274,\n",
            "        -0.2044, -0.0406, -0.1617, -0.0747, -0.0645, -0.0927, -0.0782, -0.0367,\n",
            "        -0.0964, -0.0886, -0.1250, -0.1922, -0.1236, -0.1322, -0.1156, -0.1055,\n",
            "        -0.0623, -0.0966, -0.0769, -0.1312, -0.1315, -0.1364, -0.0406, -0.0815,\n",
            "        -0.0293, -0.1126,  0.0028, -0.1250, -0.0915, -0.0650, -0.0593, -0.0792,\n",
            "        -0.0287, -0.1588, -0.0438, -0.0539, -0.1124, -0.1498, -0.1270, -0.1625,\n",
            "        -0.0156, -0.1087, -0.1117, -0.0240, -0.0621, -0.0652, -0.0295, -0.0887,\n",
            "        -0.1502, -0.0875, -0.1252, -0.0682, -0.0211, -0.0698, -0.1656, -0.0906,\n",
            "        -0.0658, -0.0723, -0.0957, -0.0705, -0.0644, -0.0896, -0.1104, -0.1204,\n",
            "        -0.0100, -0.1121, -0.1182, -0.0027, -0.0675, -0.0798, -0.0988, -0.0796,\n",
            "        -0.0773, -0.0117, -0.0401, -0.0584, -0.0493, -0.0087,  0.0326, -0.0706,\n",
            "        -0.0157, -0.0523, -0.0434, -0.0081, -0.0657, -0.0714, -0.0539,  0.0018,\n",
            "        -0.0216, -0.0792], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3lDUIYn7OJ6",
        "colab_type": "code",
        "outputId": "388cee83-4f9d-4e04-cb80-add63182316c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_loss, test_accuracy = evaluate_valid(model, fr_size, french_tokenizer, english_tokenizer)\n",
        "print(test_loss)\n",
        "print(test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0485, device='cuda:0')\n",
            "91.94797292157907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lINsORjRIu4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, vocab_size, french_tokenizer, english_tokenizer):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    accuracy = 0\n",
        "    test_error = 0\n",
        "\n",
        "    pad = english_tokenizer['<pad>']\n",
        "    \n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "    accuracy = 0\n",
        "    for src, trg in dataloaders['test']:\n",
        "        src = src.transpose(0, 1)\n",
        "        trg = trg.transpose(0, 1)\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        with torch.no_grad():\n",
        "            output, pred = model(src, trg, teacher_forcing_ratio=0.0)\n",
        "         \n",
        "        loss = F.nll_loss(output[1:].view(-1, vocab_size),trg[1:].contiguous().view(-1), ignore_index=pad)\n",
        "        total_loss += loss.data\n",
        "        \n",
        "       \n",
        "        pred = pred.float()\n",
        "        trg  = trg.float()\n",
        "        non_padding = trg.ne(pad)\n",
        "        corrects = pred.eq(trg.data).masked_select(non_padding).sum().item()\n",
        "        accuracy += corrects\n",
        "        total += non_padding.sum().item()\n",
        "        print(accuracy)\n",
        "        \n",
        "    test_error = total_loss / len(dataloaders['test'])\n",
        "    test_accuracy = ( accuracy / total  ) * 100\n",
        "    \n",
        "    \n",
        "    return test_error, test_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQlHr8JfKWTO",
        "colab_type": "code",
        "outputId": "710e326c-f9d9-40b0-fe6a-e82d2cffae4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3783
        }
      },
      "source": [
        "test_loss, test_accuracy = evaluate(model, fr_size, french_tokenizer, english_tokenizer)\n",
        "print(test_loss)\n",
        "print(test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "848\n",
            "1687\n",
            "2508\n",
            "3327\n",
            "4126\n",
            "4945\n",
            "5784\n",
            "6664\n",
            "7477\n",
            "8350\n",
            "9178\n",
            "10019\n",
            "10822\n",
            "11645\n",
            "12490\n",
            "13358\n",
            "14179\n",
            "14998\n",
            "15870\n",
            "16710\n",
            "17579\n",
            "18456\n",
            "19284\n",
            "20115\n",
            "20956\n",
            "21779\n",
            "22610\n",
            "23446\n",
            "24297\n",
            "25130\n",
            "25952\n",
            "26814\n",
            "27617\n",
            "28442\n",
            "29318\n",
            "30148\n",
            "30951\n",
            "31811\n",
            "32642\n",
            "33445\n",
            "34297\n",
            "35155\n",
            "36004\n",
            "36836\n",
            "37645\n",
            "38391\n",
            "39242\n",
            "40034\n",
            "40838\n",
            "41661\n",
            "42514\n",
            "43333\n",
            "44183\n",
            "45010\n",
            "45821\n",
            "46680\n",
            "47561\n",
            "48357\n",
            "49160\n",
            "49978\n",
            "50805\n",
            "51697\n",
            "52550\n",
            "53309\n",
            "54139\n",
            "55000\n",
            "55837\n",
            "56641\n",
            "57485\n",
            "58274\n",
            "59092\n",
            "59925\n",
            "60773\n",
            "61607\n",
            "62432\n",
            "63231\n",
            "64055\n",
            "64868\n",
            "65705\n",
            "66528\n",
            "67372\n",
            "68213\n",
            "69039\n",
            "69845\n",
            "70662\n",
            "71481\n",
            "72265\n",
            "73119\n",
            "73970\n",
            "74776\n",
            "75608\n",
            "76458\n",
            "77250\n",
            "78076\n",
            "78880\n",
            "79715\n",
            "80567\n",
            "81434\n",
            "82212\n",
            "83009\n",
            "83787\n",
            "84614\n",
            "85425\n",
            "86247\n",
            "87086\n",
            "87926\n",
            "88771\n",
            "89616\n",
            "90458\n",
            "91304\n",
            "92184\n",
            "93029\n",
            "93809\n",
            "94653\n",
            "95496\n",
            "96309\n",
            "97129\n",
            "97984\n",
            "98818\n",
            "99612\n",
            "100412\n",
            "101245\n",
            "102021\n",
            "102845\n",
            "103700\n",
            "104544\n",
            "105380\n",
            "106236\n",
            "107094\n",
            "107934\n",
            "108767\n",
            "109628\n",
            "110438\n",
            "111246\n",
            "112059\n",
            "112877\n",
            "113715\n",
            "114607\n",
            "115469\n",
            "116265\n",
            "117057\n",
            "117896\n",
            "118687\n",
            "119487\n",
            "120308\n",
            "121174\n",
            "122007\n",
            "122794\n",
            "123589\n",
            "124409\n",
            "125230\n",
            "126007\n",
            "126827\n",
            "127656\n",
            "128484\n",
            "129296\n",
            "130131\n",
            "130934\n",
            "131777\n",
            "132610\n",
            "133405\n",
            "134218\n",
            "135058\n",
            "135912\n",
            "136701\n",
            "137555\n",
            "138409\n",
            "139203\n",
            "140042\n",
            "140883\n",
            "141696\n",
            "142514\n",
            "143322\n",
            "144131\n",
            "144975\n",
            "145799\n",
            "146618\n",
            "147428\n",
            "148267\n",
            "149110\n",
            "149933\n",
            "150754\n",
            "151615\n",
            "152423\n",
            "153256\n",
            "154035\n",
            "154898\n",
            "155723\n",
            "156528\n",
            "157387\n",
            "158224\n",
            "159087\n",
            "159884\n",
            "160714\n",
            "161529\n",
            "162326\n",
            "163131\n",
            "163954\n",
            "164760\n",
            "165553\n",
            "166371\n",
            "167219\n",
            "167984\n",
            "168775\n",
            "169579\n",
            "170380\n",
            "171170\n",
            "171997\n",
            "172851\n",
            "173722\n",
            "174556\n",
            "175387\n",
            "176256\n",
            "177105\n",
            "177951\n",
            "178288\n",
            "tensor(0.2257, device='cuda:0')\n",
            "90.1259219193109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZiLs6zKHwXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class Predictor(object):\n",
        "\n",
        "    def __init__(self, model, src_vocab, tgt_vocab, src_vocab_rev, tgt_vocab_rev):\n",
        "        \"\"\"\n",
        "        Predictor class to evaluate for a given model.\n",
        "        Args:\n",
        "            model (seq2seq.models): trained model. This can be loaded from a checkpoint\n",
        "                using `seq2seq.util.checkpoint.load`\n",
        "            src_vocab (seq2seq.dataset.vocabulary.Vocabulary): source sequence vocabulary\n",
        "            tgt_vocab (seq2seq.dataset.vocabulary.Vocabulary): target sequence vocabulary\n",
        "        \"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            self.model = model.cuda()\n",
        "        else:\n",
        "            self.model = model.cpu()\n",
        "        self.model.eval()\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "        self.src_vocab_rev = src_vocab_rev\n",
        "        self.tgt_vocab_rev = tgt_vocab_rev\n",
        "\n",
        "    def get_decoder_features(self, src_seq):\n",
        "        src_id_seq = torch.LongTensor(src_seq)\n",
        "        src_id_seq = src_id_seq.transpose(0, 1)\n",
        "        \n",
        "        trg = np.zeros((1, 23), dtype=int)\n",
        "        trg = torch.LongTensor(trg)\n",
        "        trg = trg.transpose(0, 1)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            src_id_seq = src_id_seq.cuda()\n",
        "            trg = trg.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "          outputs, preds = self.model(src_id_seq, trg)\n",
        "\n",
        "        return outputs, preds\n",
        "\n",
        "\n",
        "    def predict(self, src_seq):\n",
        "        \"\"\" Make prediction given `src_seq` as input.\n",
        "        Args:\n",
        "            src_seq (list): list of tokens in source language\n",
        "        Returns:\n",
        "            tgt_seq (list): list of tokens in target language as predicted\n",
        "            by the pre-trained model\n",
        "        \"\"\"\n",
        "        outputs, preds = self.get_decoder_features(src_seq)\n",
        "\n",
        "        preds = preds.cpu().detach().numpy()\n",
        "        #tgt_id_seq = preds.transpose(0, 1)\n",
        "        tgt_id_seq = [preds[di].data[0] for di in range(1,23)]\n",
        "        tgt_seq = [self.tgt_vocab_rev[tok] for tok in tgt_id_seq]\n",
        "        \n",
        "        return tgt_seq\n",
        "\n",
        "    def predict_n(self, src_seq, n=1):\n",
        "        \"\"\" Make 'n' predictions given `src_seq` as input.\n",
        "        Args:\n",
        "            src_seq (list): list of tokens in source language\n",
        "            n (int): number of predicted seqs to return. If None,\n",
        "                     it will return just one seq.\n",
        "        Returns:\n",
        "            tgt_seq (list): list of tokens in target language as predicted\n",
        "                            by the pre-trained model\n",
        "        \"\"\"\n",
        "        other = self.get_decoder_features(src_seq)\n",
        "\n",
        "        result = []\n",
        "        for x in range(0, int(n)):\n",
        "            length = other['topk_length'][0][x]\n",
        "            tgt_id_seq = [other['topk_sequence'][di][0, x, 0].data[0] for di in range(length)]\n",
        "            tgt_seq = [self.tgt_vocab.itos[tok] for tok in tgt_id_seq]\n",
        "            result.append(tgt_seq)\n",
        "\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZY5aEJjIy0F",
        "colab_type": "code",
        "outputId": "ebd62992-5afc-43d4-bac1-f9d034b595a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predictor = Predictor(model, english_tokenizer, french_tokenizer, english_tokenizer_rev, french_tokenizer_rev)\n",
        "\n",
        "\n",
        "seq_str = \"he saw a old yellow truck .\"\n",
        "seq_str = delimit_sentence(seq_str)\n",
        "seq_str \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<sos> he saw a old yellow truck . <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mblRoNYB5onh",
        "colab_type": "code",
        "outputId": "bd3163ca-c9b1-46d9-a861-3b63104ef857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#seq = seq_str.strip().split()\n",
        "seq = []\n",
        "for word in seq_str.split():\n",
        "    if word not in punctuation:\n",
        "       seq.append(word)\n",
        "\n",
        "  \n",
        "seq = [english_tokenizer[tok] for tok in seq]\n",
        "seq"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 28, 130, 102, 113, 114, 103, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEuk3dbS98Yd",
        "colab_type": "code",
        "outputId": "b2523bd4-f6e7-4441-9d8b-a843a7d3201a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "feature = np.zeros((1, 23), dtype=int)\n",
        "trunc = seq[:23]\n",
        "feature[:, :len(trunc)] = trunc\n",
        "feature "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  2,  28, 130, 102, 113, 114, 103,   3,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEirjw3XUuqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_id_seq = torch.LongTensor([feature]).view(1, -1)\n",
        "src_id_seq = src_id_seq.transpose(0, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6U5RGG3WWgo",
        "colab_type": "code",
        "outputId": "7971edd6-b9b8-43e4-b108-f0ed7a00faf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "src_id_seq"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  2],\n",
              "        [ 28],\n",
              "        [130],\n",
              "        [102],\n",
              "        [113],\n",
              "        [114],\n",
              "        [103],\n",
              "        [  3],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85eQuKXmVHhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_id_seq = src_id_seq.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7ZS6RoRVRaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trg = np.zeros((1, 23), dtype=int)\n",
        "trg = torch.LongTensor(trg)\n",
        "trg = trg.transpose(0, 1)\n",
        "trg = trg.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on82LniEVjPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "     outputs, preds = model(src_id_seq, trg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL5MJxENVjXw",
        "colab_type": "code",
        "outputId": "7b86f900-c850-49bc-e5f6-b32bc41d5ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "preds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0.],\n",
              "        [  5.],\n",
              "        [119.],\n",
              "        [151.],\n",
              "        [146.],\n",
              "        [186.],\n",
              "        [111.],\n",
              "        [135.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [111.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXxyCeaKVjey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = preds.cpu().detach().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWXdQfyRWyxT",
        "colab_type": "code",
        "outputId": "b67d21cc-aa44-459b-aee7-72cbd0654438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "preds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0.],\n",
              "       [  5.],\n",
              "       [119.],\n",
              "       [151.],\n",
              "       [146.],\n",
              "       [186.],\n",
              "       [111.],\n",
              "       [135.],\n",
              "       [  3.],\n",
              "       [  3.],\n",
              "       [  3.],\n",
              "       [  3.],\n",
              "       [  3.],\n",
              "       [  3.],\n",
              "       [  3.],\n",
              "       [  3.],\n",
              "       [111.],\n",
              "       [  3.],\n",
              "       [  3.],\n",
              "       [  3.],\n",
              "       [  3.],\n",
              "       [  3.],\n",
              "       [  3.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imig8RzEA9rX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xxx, yyy = predictor.get_decoder_features(feature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6XftfT0WH1A",
        "colab_type": "code",
        "outputId": "2822163f-6c8f-4924-88b4-f13d3ade6301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "yyy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0.],\n",
              "        [  5.],\n",
              "        [119.],\n",
              "        [151.],\n",
              "        [146.],\n",
              "        [146.],\n",
              "        [186.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.],\n",
              "        [  3.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH2LkV7DR-hq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = yyy.cpu().detach().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vy5qwHSxXEqL",
        "outputId": "a90d66a5-2387-4fdd-af07-705ab0514f89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "\n",
        "tgt_id_seq = [preds[di].data[0] for di in range(1,23)]\n",
        "tgt_id_seq"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.0,\n",
              " 119.0,\n",
              " 151.0,\n",
              " 146.0,\n",
              " 146.0,\n",
              " 186.0,\n",
              " 3.0,\n",
              " 3.0,\n",
              " 3.0,\n",
              " 3.0,\n",
              " 3.0,\n",
              " 3.0,\n",
              " 3.0,\n",
              " 3.0,\n",
              " 3.0,\n",
              " 3.0,\n",
              " 3.0,\n",
              " 3.0,\n",
              " 3.0,\n",
              " 3.0,\n",
              " 3.0,\n",
              " 3.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5R2N_2__nLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = predictor.predict(feature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9KLr2ff_sCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tgt_seq_output = ' '.join([word for word in output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7si__n6_38O",
        "colab_type": "code",
        "outputId": "179d7217-1eb9-4f33-9387-4ae0ea62356f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tgt_seq_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'il a vu un vieux camion jaune <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKyzAkmy4VOL",
        "colab_type": "code",
        "outputId": "1723a587-91d3-420e-b5b7-4c2d10e7e276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(predictor.predict(feature))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['il', 'a', 'vu', 'un', 'vieux', 'camion', 'jaune', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdr-4CwQAS6J",
        "colab_type": "code",
        "outputId": "eed5d097-dd3f-4779-cb32-09afd37e0c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "seq_str = \"new jersey is sometimes quiet during autumn , and it is snowy in april .\"\n",
        "seq_str = delimit_sentence(seq_str)\n",
        "seq_str "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<sos> new jersey is sometimes quiet during autumn , and it is snowy in april . <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bieJXC0sAW2E",
        "colab_type": "code",
        "outputId": "93d71628-6ba8-4872-9ba6-a9ebe2e30f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "seq = []\n",
        "for word in seq_str.split():\n",
        "    if word not in punctuation:\n",
        "       seq.append(word)\n",
        "\n",
        "  \n",
        "seq = [english_tokenizer[tok] for tok in seq]\n",
        "seq"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 19, 25, 1, 10, 69, 6, 41, 9, 5, 1, 57, 4, 46, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MdLxoDiAa99",
        "colab_type": "code",
        "outputId": "b7331792-b0b6-4185-906e-3178ecbfada8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "feature = np.zeros((1, 23), dtype=int)\n",
        "trunc = seq[:23]\n",
        "feature[:, :len(trunc)] = trunc\n",
        "feature "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2, 19, 25,  1, 10, 69,  6, 41,  9,  5,  1, 57,  4, 46,  3,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8ESaVTZBqvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xxx, yyy = predictor.get_decoder_features(feature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b18FW0lVB0EY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = yyy.cpu().detach().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8c5k5qSGFMB",
        "colab_type": "code",
        "outputId": "95d94f30-3459-4b6a-f0e8-427ccb2db4f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "tgt_id_seq = [preds[di].data[0] for di in range(1,23)]\n",
        "tgt_id_seq"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[36.0,\n",
              " 35.0,\n",
              " 1.0,\n",
              " 10.0,\n",
              " 68.0,\n",
              " 38.0,\n",
              " 13.0,\n",
              " 26.0,\n",
              " 8.0,\n",
              " 5.0,\n",
              " 113.0,\n",
              " 4.0,\n",
              " 50.0,\n",
              " 3.0,\n",
              " 50.0,\n",
              " 3.0,\n",
              " 4.0,\n",
              " 3.0,\n",
              " 3.0,\n",
              " 50.0,\n",
              " 3.0,\n",
              " 4.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iUjY6hbeJTN3",
        "colab": {}
      },
      "source": [
        "output = predictor.predict(feature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0nUGRBudJTN8",
        "outputId": "80c0f471-e95a-4733-b4a2-effa3edbb5f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tgt_seq_output = ' '.join([word for word in output])\n",
        "tgt_seq_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"new jersey est parfois calme pendant l' automne et il est neigeux en juillet <eos> juillet juillet juillet juillet <eos> juillet <eos>\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    }
  ]
}